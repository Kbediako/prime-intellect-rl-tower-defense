# Results — Prime Intellect RL Tower Defense

> Status: **SingleTurn diagnostics concluded**; macro-round multi-turn is the primary training interface. Episode-length validation remains **inconclusive beyond cap** (X44/X45/X46b/X47b/X49/X53/X55/X57/X59/X61/X63/X65/X67/X69/X73/X75/X77 hit observed caps at 20/22/24/26/28/30/30/30/32/34/36/36/38/38/38/40/42). Horizon probes still show intermittent sample-upload 500s on some runs (X51 no samples; X53 partial samples; X55 partial samples; X63 missing step-20 samples; X67 missing step 0/20/40 samples; X69 missing step 0 samples), while the reliability-first horizon lane now includes high-cap runs with full samples at 30/32/34/36/38/40/42 (X57/X59/X61/X65/X73/X75/X77). Adaptive late-phase mix target (upgrade-leaning with build presence, ~15-25% upgrade lead) is still best represented by X52 (lower bound), X66 (lower bound), X70 (upper bound), and X72 (upper bound), while X71 remains invalid for policy analysis due persistent truncation/format failures.
> Horizon measurement semantics: with `difficulty.max_rounds = N`, observed episode length is right-censored at `N`; cap-hit runs prove only a lower bound (`true horizon >= N`). To test beyond-cap gains, raise `max_rounds` in the horizon lane while keeping payload-safe controls fixed.

## Run Snapshot

| Run | Status | Run ID | Base Model | Env ID | Env Version | Config | Primary Delta |
| --- | --- | --- | --- | --- | --- | --- | --- |
| A | completed | `cpe5e60oplhmtdsa3byqc6ro` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.1` | `configs/lab/prime-td-run-a.toml` | baseline weights + sampling |
| B | completed | `y788w0uxqiormzp81q1poq41` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.1` | `configs/lab/prime-td-run-b.toml` | tuned weights + tighter sampling |
| C | stopped | `dw5b1xkhx8sj4ny9ljgvvqml` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.1` | `configs/lab/prime-td-run-c.toml` | rollout_steps=0 curriculum change |
| D | stopped | `ds2s6uije2q9z4t9ny1e70fb` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.1` | `configs/lab/prime-td-run-d.toml` | rollout_steps=0 + lower step penalty |
| E | completed | `xc662lm8afgdz25dc0a7dhdu` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.1` | `configs/lab/prime-td-run-e.toml` | rollout_steps=1 diagnostic |
| F | completed | `u1uxany3ub4g7gab3aofd7gh` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.1` | `configs/lab/prime-td-run-f.toml` | rollout_steps=1 + lower step penalty |
| H | stopped | `z95gkb5x662h6selsv4125rn` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.1` | `configs/lab/prime-td-run-h.toml` | lookahead_rounds=8, weight=0.5 |
| J | completed | `x1ctjo6uvbqmdbpomn76zxfw` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.1` | `configs/lab/prime-td-run-j.toml` | lookahead_rounds=2, weight=0.5 + rollout_steps=4 |
| K | completed | `eqjqeuhswcenpnt3vdvythig` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.2` | `configs/lab/prime-td-auto-advance-80-k.toml` | auto-advance + prep budget (2 → scale 0.1, max 6) |
| L | completed | `ogxpb2r9sylec7sl9c9a9xu2` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.2` | `configs/lab/prime-td-auto-advance-80-l.toml` | auto-advance + higher prep budget (3 → scale 0.15, max 8) |
| M | completed | `a6vzmamlqca13wcziu9zlero` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.2` | `configs/lab/prime-td-auto-advance-80-m.toml` | rollout_steps=9 (target round ~5, remaining=1) |
| N | completed | `bwyppq2uq9qhjw9i91kyc8k4` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.2` | `configs/lab/prime-td-auto-advance-80-n.toml` | max_build_slots=12 (compress build action space) |
| O | completed | `i1lpujti4rwhd52qp1d5cnde` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.3` | `configs/lab/prime-td-auto-advance-80-o.toml` | reward credit: auto-advance round completion in rubric |
| P | completed | `cxysr9i9p16oz5co0l6lvl9a` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.3` | `configs/lab/prime-td-auto-advance-80-p.toml` | dataset.policy=bootstrap for decision-relevant prompts |
| Q | completed | `ns3xax5y1gpvlcmuv5j6ando` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.7` | `configs/lab/prime-td-auto-advance-80-q.toml` | dataset.policy=noop_then_start (round ~5, prep remaining=1) |
| R | completed | `eonmjp6nrmq1mphz2n93779i` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.7` | `configs/lab/prime-td-auto-advance-80-r.toml` | noop_then_start + start_round_max_prep_remaining=1 (enforced) |
| S | completed | `rouzhjav619vbwxazzkx9fzs` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.10` | `configs/lab/prime-td-auto-advance-80-s.toml` | max_build_slots=3 + higher exploration |
| T | completed | `qud3jsz07g060aiumnvowsbv` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.10` | `configs/lab/prime-td-auto-advance-80-t.toml` | cash-scarce economy to force upgrades |
| U | completed | `xzmgqle5c5c68jp3d2bpukn8` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.11` | `configs/lab/prime-td-auto-advance-80-u.toml` | diverse snapshot dataset + dominance diagnostic |
| V | completed | `g5ylvtzgn2m7wa4710l4nkb2` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.11` | `configs/lab/prime-td-macro-round-30-v.toml` | macro-round multi-turn diagnostic |
| W | completed | `ljq5em3x4m8iuk84s30miz80` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.13` | `configs/lab/prime-td-auto-advance-80-w.toml` | SingleTurn snapshot run (rounds 15/20, decision filter disabled) |
| X | failed (no samples) | `jdgigcvppsiq09b7af5tqp3d` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.13` | `configs/lab/prime-td-macro-round-60-x.toml` | macro-round diagnostic; rollouts returned 0 samples |
| X2 | stopped (no samples) | `vo84e6ikhq9u9hc98y2gm2i1` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.13` | `configs/lab/prime-td-macro-round-60-x.toml` | macro-round rerun; logs showed 500s on sample uploads |
| X3 | stopped (no samples) | `aqubxfcdpwhg69efxofqjhrw` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.13` | `configs/lab/prime-td-macro-round-60-x.toml` | rerun with max_tokens=64, rollouts_per_example=1, smaller prompts |
| X4 | completed (format-invalid) | `ddr57p562fj7o4g6dryodlat` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.13` | `configs/lab/prime-td-macro-round-60-x.toml` | rerun with max_tokens=32, rounds=[10,15], max_rounds=15, smaller prompts |
| X5 | completed (format-invalid) | `c20w0kwl9lu8ldgdiphmfkra` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.13` | `configs/lab/prime-td-macro-round-60-x.toml` | rerun with max_tokens=48, rounds=[10,15], max_rounds=15, smaller prompts |
| X6 | completed (valid plans, invalid actions) | `xinrtc6zvjy28t7974st4tsj` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.13` | `configs/lab/prime-td-macro-round-60-x.toml` | parallel run with max_tokens=96, same caps |
| X7 | stopped (no samples) | `ddjewl8c12ixol8pizpri5e6` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.13` | `configs/lab/prime-td-macro-round-60-x7.toml` | choose-index plans, max_tokens=64, max_rounds=20 |
| X8 | stopped (no samples) | `ho9d66h4359hte2q41ull6an` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.13` | `configs/lab/prime-td-macro-round-60-x8.toml` | choose-index plans, max_tokens=96, max_rounds=20 |
| X9 | stopped (no samples) | `l9n63uciqylm5c8kmsqa8hsm` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.13` | `configs/lab/prime-td-macro-round-60-x9.toml` | choose-index plans, max_tokens=32, batch_size=8 |
| X10 | stopped (no samples) | `aadtrwgfor3no3iank7njtqw` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.13` | `configs/lab/prime-td-macro-round-60-x10.toml` | choose-index plans, max_tokens=48, batch_size=8 |
| X11 | completed (rounds stalled) | `p4ovp2yk1tx4cisez61ein86` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.14` | `configs/lab/prime-td-macro-round-60-x11.toml` | choose-index plans, max_rounds=16, max_tokens=64, batch_size=16 |
| X12 | completed (rounds stalled) | `tec5wov4528pqk1jfknl73gr` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.14` | `configs/lab/prime-td-macro-round-60-x12.toml` | choose-index plans, max_rounds=16, max_tokens=96, batch_size=16 |
| X13 | stopped (interleaved) | `z3ggo2k2op99xr57s2t3nzfp` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.16` | `configs/lab/prime-td-macro-round-60-x13.toml` | interleaved warning persisted; rounds stalled (delta 0) |
| X14 | stopped (interleaved) | `dva1t7dejvtxdk6mklmhfrlt` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.16` | `configs/lab/prime-td-macro-round-60-x14.toml` | interleaved warning persisted; rounds stalled (delta 0) |
| X15 | stopped (interleaved) | `hl0z9ab4a68ii54gx7pbzy4f` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.17` | `configs/lab/prime-td-macro-round-60-x15.toml` | interleaved warning persisted; rounds likely stalled |
| X16 | stopped (interleaved) | `pze7enmlf1vgvkuslpyv579x` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.17` | `configs/lab/prime-td-macro-round-60-x16.toml` | interleaved warning persisted; rounds likely stalled |
| X17 | completed | `dinkirjvsnwwzfx2wkmf3w9p` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.18` | `configs/lab/prime-td-macro-round-60-x17.toml` | non-interleaved macro-round, filtered candidates, max_tokens=64 |
| X18 | completed | `emhsyysqgiayso0cga9mfgdj` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.18` | `configs/lab/prime-td-macro-round-60-x18.toml` | non-interleaved macro-round, filtered candidates, max_tokens=96 |
| X19 | stopped (no samples) | `xzrhblbnx516kusdbm9nbfd9` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.18` | `configs/lab/prime-td-macro-round-60-x19.toml` | candidate balance + soft cap; max_rounds=24 caused oversized completions (500s) |
| X20 | stopped (no samples) | `ypjb7kxzh701fd0ju1e2bzrn` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.18` | `configs/lab/prime-td-macro-round-60-x20.toml` | stronger balance; max_rounds=24 caused oversized completions (500s) |
| X21 | completed (samples at step 0 only; 500s after step 10) | `umxk16fllh8t925x4jw5usp5` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.18` | `configs/lab/prime-td-macro-round-60-x21.toml` | candidate balance + soft cap; max_rounds=18 |
| X22 | stopped (no samples) | `f4mjslk5ww900qs9xybd7hna` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.18` | `configs/lab/prime-td-macro-round-60-x22.toml` | stronger balance; max_rounds=18, max_tokens=64 (500s) |
| X23 | completed | `ex7jobk9catq1nbaeic4zljt` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.18` | `configs/lab/prime-td-macro-round-60-x23.toml` | stronger balance; max_rounds=16, max_tokens=48 |
| X24 | completed | `t0vh9pd4c1x413jxpnxtuky9` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.18` | `configs/lab/prime-td-macro-round-60-x24.toml` | redo X21 with lower payload + soft cap; `trajectory_strategy=interleaved` (relaunch) |
| X25 | completed | `j7pttou1w8589wezwr7m63e0` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.18` | `configs/lab/prime-td-macro-round-60-x25.toml` | higher build frac + upgrade caps + longer safe_explore build; `trajectory_strategy=branching` |
| X26 | stopped (500s; deleted) | `onpj7d9zujtas2gyezdc2ody` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.18` | `configs/lab/prime-td-macro-round-60-x26.toml` | horizon test; max_rounds=18; hit upload 500s |
| X26b | stopped (500s; deleted) | `hkdt63q8gvm73zk0q80b8ws3` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.18` | `configs/lab/prime-td-macro-round-60-x26b.toml` | horizon test retry; max_rounds=17 + tighter observation caps; hit 500s |
| X27 | stopped (500s; deleted) | `kbku4pzmgxrrlt6v00knj5hw` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.18` | `configs/lab/prime-td-macro-round-60-x27.toml` | stronger early build bias; hit 500s |
| X26c | stopped (truncation; deleted) | `ahq5xayugi7ibo1ofgtpjv9q` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.18` | `configs/lab/prime-td-macro-round-60-x26c.toml` | payload-tightened baseline; max_tokens=32 caused format truncation |
| X27b | stopped (truncation risk; deleted) | `mni7hyfs7tjxnh41v5ojyyob` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.18` | `configs/lab/prime-td-macro-round-60-x27b.toml` | stopped after X26c truncation signal |
| X26d | completed | `yb058zzb4odhdz69ox2dunjz` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.18` | `configs/lab/prime-td-macro-round-60-x26d.toml` | payload‑stable retry; max_tokens=40; tight caps; `trajectory_strategy=branching` |
| X27c | completed | `wjqmxxhozj9pokemdkupdz13` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.18` | `configs/lab/prime-td-macro-round-60-x27c.toml` | stronger early build bias; max_tokens=40; tight caps; `trajectory_strategy=branching` |
| X28 | stopped (500s) | `qlgelc48t1hnz5qx0d5a6vf1` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.18` | `configs/lab/prime-td-macro-round-60-x28.toml` | episode‑length probe; max_rounds=18; tight caps; `trajectory_strategy=branching` |
| X28b | completed (intermittent 500s) | `pt54lbjrcqkvi4z96od3ncfb` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.18` | `configs/lab/prime-td-macro-round-60-x28b.toml` | episode‑length probe; batch_size=8; tighter caps; max_rounds=18 |
| X29 | stopped (500s) | `l8o0eoxn02hxbhpzh0k6z5gz` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.18` | `configs/lab/prime-td-macro-round-60-x29.toml` | late‑phase mix nudge; max_rounds=18; payload‑reduced caps |
| X29b | completed | `bj8966t8ymaluccsvn2cwj3r` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.18` | `configs/lab/prime-td-macro-round-60-x29b.toml` | late‑phase mix nudge + batch_size=4; tightest caps; max_rounds=18 |
| X30 | completed | `fg1tujh491j736mq9bg0evea` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.18` | `configs/lab/prime-td-macro-round-60-x30.toml` | X26d behavioral baseline + X29b payload controls; max_rounds=18 |
| X31 | completed | `pu1v7q9evjrh8ij59kv7h2bx` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.18` | `configs/lab/prime-td-macro-round-60-x31.toml` | X26d baseline + late‑phase mix nudge; batch_size=4; max_rounds=18 |
| X32 | completed | `ydiylivcgzume5wk445g6rj3` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.18` | `configs/lab/prime-td-macro-round-60-x32.toml` | aggressive build bias under payload caps; batch_size=4; max_rounds=18 |
| X33 | completed | `z90upu7c2yx5a2zyh6qc1uk5` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.18` | `configs/lab/prime-td-macro-round-60-x33.toml` | aggressive build bias + stronger safe_explore prior; batch_size=4; max_rounds=18 |
| X34 | completed | `fer1svk36hya7kih1x19lldf` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.18` | `configs/lab/prime-td-macro-round-60-x34.toml` | late‑phase clamp (overall 0.6/3; early 0.7/2, mid 0.6/2, late 0.7/2); batch_size=4; max_rounds=18 |
| X35 | completed | `l4mzckq1j8cncl7u3qqaw71r` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.18` | `configs/lab/prime-td-macro-round-60-x35.toml` | build availability boost (max_action_candidates=6, max_build_slots=3) with balance 0.6/3; batch_size=4; max_rounds=18 |
| X36 | completed | `zxqi7bskg48j5gx4o9g7vyno` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.18` | `configs/lab/prime-td-macro-round-60-x36.toml` | late upgrade‑leaning w/ build floor (late min_build_frac=0.25, max_upgrade_candidates=4); batch_size=4; max_rounds=18 |
| X37 | completed | `dszrlojwleae536fzo3rimsn` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.18` | `configs/lab/prime-td-macro-round-60-x37.toml` | **build‑leaning baseline** (late balanced); max_build_slots=3, snapshots [12,16]; batch_size=4; max_rounds=18 |
| X38 | completed | `watmtno5atltqppgwx7oq0s7` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.18` | `configs/lab/prime-td-macro-round-60-x38.toml` | late upgrade‑leaning (late min_build_frac=0.30, max_upgrade_candidates=4) with snapshots [12,16] |
| X39 | completed | `hn1dm10r2s46pn0kosyizh6z` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.18` | `configs/lab/prime-td-macro-round-60-x39.toml` | stronger late upgrade‑leaning (late min_build_frac=0.25, max_upgrade_candidates=5) with snapshots [12,16] |
| X40 | completed | `lu6ydpitdtw01w20le4ta3a4` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.18` | `configs/lab/prime-td-macro-round-60-x40.toml` | late near‑parity (late min_build_frac=0.30, max_upgrade_candidates=3) with snapshots [12,16] |
| X41 | completed | `exwrtnd147o8u66vt5dnoi9f` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.18` | `configs/lab/prime-td-macro-round-60-x41.toml` | late near‑parity (late min_build_frac=0.29, max_upgrade_candidates=4) with snapshots [12,16]; step 0 had no samples |
| X42 | completed | `d9j37xv9s07ian59ziyoz7x3` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.18` | `configs/lab/prime-td-macro-round-60-x42.toml` | late target probe (late min_build_frac=0.30, max_upgrade_candidates=4) with snapshots [12,16] |
| X43 | completed | `k8bg50ecudykctj48ryedaoz` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.18` | `configs/lab/prime-td-macro-round-60-x43.toml` | late target probe (late min_build_frac=0.29, max_upgrade_candidates=3) with snapshots [12,16] |
| X44 | completed | `p42ky7ibnnr52fm5yzxllhes` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.18` | `configs/lab/prime-td-macro-round-60-x44.toml` | episode‑length probe (max_rounds=20) using X43 baseline |
| X45 | completed | `rqkultap39xvj8ngq0fyy0k1` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.18` | `configs/lab/prime-td-macro-round-60-x45.toml` | episode‑length probe (max_rounds=22) using X43 baseline |
| X46 | stopped + deleted (500s) | `t3nlprqwjim2okcim6qwzp2d` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.18` | `configs/lab/prime-td-macro-round-60-x46.toml` | episode‑length probe (max_rounds=24); failed on upload 500s |
| X47 | stopped + deleted (500s) | `yx7icez3h2ratiklyfy3oqru` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.18` | `configs/lab/prime-td-macro-round-60-x47.toml` | episode‑length probe (max_rounds=26); failed on upload 500s |
| X46b | completed | `lozcb7xg62lovah0khh6xwp1` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.18` | `configs/lab/prime-td-macro-round-60-x46b.toml` | episode‑length probe retry (max_rounds=24, batch_size=2) |
| X47b | completed | `s89xetmwo9kz12344g3ahegk` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.18` | `configs/lab/prime-td-macro-round-60-x47b.toml` | episode‑length probe retry (max_rounds=26, batch_size=2) |
| X48 | completed | `tydn3z6mbziugdpf4rmn3i65` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.18` | `configs/lab/prime-td-macro-round-60-x48.toml` | late-phase ratio calibration (late min_build_frac=0.295, max_upgrade_candidates=3) |
| X49 | completed (step 40 sample upload 500) | `kvbr2r2jo431owjoytccr4rw` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.18` | `configs/lab/prime-td-macro-round-60-x49.toml` | episode-length probe (max_rounds=28, batch_size=2) carrying X48 late mix |
| X50 | completed | `sqfh70lt1nbp8n7bjmdls1iw` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.18` | `configs/lab/prime-td-macro-round-60-x50.toml` | late-phase correction (late min_build_frac=0.32, max_upgrade_candidates=3) |
| X51 | completed (no samples; repeated sample upload 500s) | `kvyrkg3erl6yy72o5g2ljioc` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.18` | `configs/lab/prime-td-macro-round-60-x51.toml` | episode-length probe (max_rounds=30, batch_size=2) carrying X50 late mix |
| X52 | completed | `dc364f3ugz42snhey1m9dd8s` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.18` | `configs/lab/prime-td-macro-round-60-x52.toml` | adaptive late-phase calibration (late min_build_frac=0.35, max_upgrade_candidates=3) |
| X53 | completed (partial samples; sample upload 500s at steps 0/20/30) | `n7ryszjxt4mc2notva686x81` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.18` | `configs/lab/prime-td-macro-round-60-x53.toml` | max_rounds=30 horizon probe with stricter observation payload caps |
| X54 | completed | `rx19kk1zx6nspnt1evtrgljf` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.18` | `configs/lab/prime-td-macro-round-60-x54.toml` | behavior-lane calibration around adaptive late target center (late min_build_frac=0.34, max_upgrade_candidates=3) |
| X55 | completed (partial samples; sample upload 500s at steps 0/30/50) | `ixxzcocxw63ldm3dnvsyx2mi` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.18` | `configs/lab/prime-td-macro-round-60-x55.toml` | max_rounds=30 horizon probe carrying X54 late mix with moderated payload caps |
| X56 | completed | `ve1jc2gbw4qbt156kjhrn07f` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.18` | `configs/lab/prime-td-macro-round-60-x56.toml` | behavior-lane re-anchor to X52 target mix |
| X57 | completed | `za3gzloxpcbnen5569hweg61` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.18` | `configs/lab/prime-td-macro-round-60-x57.toml` | reliability-first horizon probe (`batch_size=1`, snapshots [14,18]) carrying X52 late mix |
| X58 | completed | `h3r60z8yudqphntd9fzbopj9` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.18` | `configs/lab/prime-td-macro-round-60-x58.toml` | behavior-lane refinement from X52 (late `max_upgrade_candidates=4`) |
| X59 | completed | `qufw80jvuzy04e5xm52fhq2l` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.18` | `configs/lab/prime-td-macro-round-60-x59.toml` | reliability-first horizon progression (`max_rounds=32`, `batch_size=1`) |
| X60 | completed | `ihs7ugrp6m3t6x05raszs2fd` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.18` | `configs/lab/prime-td-macro-round-60-x60.toml` | behavior-lane retune from X58 with stronger late build floor |
| X61 | completed | `xb1nvxg3o9zz2x34qciqrlcr` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.18` | `configs/lab/prime-td-macro-round-60-x61.toml` | reliability-first horizon progression (`max_rounds=34`, `batch_size=1`) |
| X62 | completed | `kt8szeteixlxd9eg3i6qjd9c` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.18` | `configs/lab/prime-td-macro-round-60-x62.toml` | behavior-lane retune from X60 (late `min_build_frac=0.39`, `max_upgrade_candidates=4`) |
| X63 | completed (step 20 samples missing; upload 500) | `rogycwef5ouzhbj3mbbr51ru` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.18` | `configs/lab/prime-td-macro-round-60-x63.toml` | reliability-first horizon progression (`max_rounds=36`, `batch_size=1`) |
| X64 | completed | `tk4ffny3aag33tdlvtx6ib47` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.18` | `configs/lab/prime-td-macro-round-60-x64.toml` | behavior-lane retune from X62 (late `min_build_frac=0.36`, `max_upgrade_candidates=5`) |
| X65 | completed | `emw80z7hb1123l3wqe6cqy3p` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.18` | `configs/lab/prime-td-macro-round-60-x65.toml` | reliability-first horizon progression (`max_rounds=36`, `batch_size=1`, reduced payload caps) |
| X66 | completed | `ktjauq2lx3xzm8xec03okj24` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.19` | `configs/lab/prime-td-macro-round-60-x66.toml` | behavior-lane refinement from X64 (late `min_build_frac=0.38`, `max_upgrade_candidates=4`) |
| X67 | completed (partial samples; upload 500 at steps 0/20/40) | `wpb6r4x9he1nzmxbqdfxwjfh` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.19` | `configs/lab/prime-td-macro-round-60-x67.toml` | reliability-first horizon progression (`max_rounds=38`, `batch_size=1`, X65 payload controls) |
| X68 | completed | `a7sre56kqbvb3xz48eyg1de6` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.19` | `configs/lab/prime-td-macro-round-60-x68.toml` | behavior-lane refinement from X66 (late `min_build_frac=0.37`, `max_upgrade_candidates=4`) |
| X69 | completed (step 0 samples missing; upload 500 at step 0 sample post) | `q9zubvghcurv9moam8ey9h70` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.19` | `configs/lab/prime-td-macro-round-60-x69.toml` | reliability-first horizon retry (`max_rounds=38`) with tighter observation payload caps |
| X70 | completed | `y1ko3j91odfs1sljd0ep7nds` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.19` | `configs/lab/prime-td-macro-round-60-x70.toml` | behavior-lane interpolation from X66/X68 (late `min_build_frac=0.377`, `max_upgrade_candidates=4`) |
| X71 | completed (policy-invalid: persistent truncation/format failures) | `ovhep1ox0xkif31gp0vsu12r` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.19` | `configs/lab/prime-td-macro-round-60-x71.toml` | stricter-payload horizon retry (`max_rounds=38`, `max_tokens=32`, lower observation caps, later snapshots [16,20]) |
| X72 | completed | `lh85h7erg0s1740t16pne7z4` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.19` | `configs/lab/prime-td-macro-round-60-x72.toml` | behavior-lane midpoint probe from X66/X70 (late `min_build_frac=0.378`, `max_upgrade_candidates=4`) |
| X73 | completed | `j5oydpr582dck13jblmdwq7m` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.19` | `configs/lab/prime-td-macro-round-60-x73.toml` | horizon-lane retry at `max_rounds=38` with safe token budget (`max_tokens=40`) and payload-tight observations |
| X74 | completed (step-20 partial samples: 2/4) | `o6obbmmtsyhfb3qaxny7nc5e` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.19` | `configs/lab/prime-td-macro-round-60-x74.toml` | behavior-lane center-of-band probe from X72 (late `min_build_frac=0.382`, `max_upgrade_candidates=4`) |
| X75 | completed | `xq1xk3mcui3nl84e2drdgoqm` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.19` | `configs/lab/prime-td-macro-round-60-x75.toml` | horizon-lane cap probe (`max_rounds=40`) with strict payload controls from X73/X69 |
| X76 | completed | `xqs8b45jqgl4b1n58duqfm19` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.19` | `configs/lab/prime-td-macro-round-60-x76.toml` | behavior-lane recenter from X74 toward X70/X72 (late `min_build_frac=0.379`, `max_upgrade_candidates=4`) |
| X77 | completed | `pzk2urzgf0nx1zkthpv8ex9g` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.19` | `configs/lab/prime-td-macro-round-60-x77.toml` | reliability-first horizon extension from X75 (`max_rounds=42`) with unchanged payload controls |
| X78 | running | `x1td9k7eyllyqxrakglcqdp5` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.19` | `configs/lab/prime-td-macro-round-60-x78.toml` | behavior-lane re-anchor to X70 settings (late `min_build_frac=0.377`, `max_upgrade_candidates=4`) |
| X79 | running | `kwq5knmc1h818fynlwuazovr` | `Qwen/Qwen3-4B-Instruct-2507` | `kbediako/prime-td-env` | `0.2.19` | `configs/lab/prime-td-macro-round-60-x79.toml` | reliability-first horizon extension from X77 (`max_rounds=44`) with unchanged payload controls |

## Run A Snapshot (exact config)

- **Run ID:** `cpe5e60oplhmtdsa3byqc6ro`
- **Base model:** `Qwen/Qwen3-4B-Instruct-2507`
- **Env ID:** `kbediako/prime-td-env`
- **Env version:** `0.2.1` (see `pyproject.toml`, wheel SHA in `.prime/.env-metadata.json`)
- **Config:** `configs/lab/prime-td-run-a.toml`
- **Sampling:** `temperature=0.2`, `max_tokens=64`
- **Reward weights:** `reward_weights.env=1.0`, `reward_weights.format=0.5`
- **Step penalty:** `0.1`
- **Dataset rollout:** `rollout_steps=2`, `policy=random`
- **Eval cadence:** every 20 steps, held-out seeds start at `1000`

## A vs B — Controlled Change

Primary delta (intended):
- **Lower format weight + higher step penalty** in B (`format=0.25`, `step_penalty=0.2`).

Secondary deltas (explicit):
- **Tighter sampling** in B (`temperature=0.15`, `max_tokens=48`).
- **Run C** keeps B settings but sets `dataset.rollout_steps=0` to remove tower-seeded prompts.
- **Run D** keeps C settings but lowers `step_penalty` back to `0.1`.
- **Run E** uses `rollout_steps=1` (single-step curriculum) with B reward settings.
- **Run F** uses `rollout_steps=1` with lower `step_penalty=0.1`.

## Eval Protocol (fixed + deterministic)

- **Train seeds:** `0..63` (64 examples)
- **Held-out eval seeds:** `1000..1049` (50 examples)
- **Random suite:** `2000..2019` (20 examples)
- **Metrics:** avg_round, win_rate, lives_remaining, invalid_json_rate, invalid_action_rate, truncation_rate
- **Eval command:** see “Repro commands” in this doc once run completes

## Metrics (placeholders)

| Run | Avg Round | Win Rate | Avg Lives | Avg Reward | Invalid JSON | Invalid Action | Truncation |
| --- | --- | --- | --- | --- | --- | --- | --- |
| A (early) | TBD | TBD | TBD | 92.17 | 0.00 | TBD | 0.00 |
| A (late) | TBD | TBD | TBD | 103.58 | 0.00 | TBD | 0.00 |
| B (early) | TBD | TBD | TBD | 25.62 | 0.00 | TBD | 0.00 |
| B (late) | TBD | TBD | TBD | 0.05 | 0.00 | TBD | 0.00 |

## Rollout Snippets (placeholders)

1) **Snippet A1 (step 0, reward 0.4):** `{"type":"build","tower_type":"dart","x":8,"y":3}`
   - **Demonstrates:** format-stable build action at episode start.
2) **Snippet A2 (step 40, reward 110.4):** `{"type":"start_round"}`
   - **Demonstrates:** high reward for advance action once towers are seeded in prompt.
3) **Snippet A3 (step 70, reward 110.4):** `{"type":"start_round"}`
   - **Demonstrates:** continued reliance on advance action; action diversity to monitor.
4) **Snippet B1 (step 0, reward 0.05):** `{"type":"build","tower_type":"dart","x":3,"y":2}`
   - **Demonstrates:** format-stable build action in Run B early phase.
5) **Snippet B2 (step 70, reward 0.05):** `{"type":"build","tower_type":"dart","x":3,"y":1}`
   - **Demonstrates:** Run B remained build-heavy with low reward late in training.

## Known Observations / Open Checks

- Run A action mix (steps 0/40/70): `start_round=17`, `build=7`, `invalid_json_rate=0.0`. Likely driven by `rollout_steps=2` seeding towers in the prompt (so “advance” is locally good). We will verify whether this reduces build/upgrade diversity and adjust in later runs if needed.
- Run B action mix (steps 0/40/70): `build=23`, `start_round=1`, `invalid_json_rate=0.0`. Late-phase reward collapsed to ~0.05; needs follow-up run or config tweak if this persists.
- Runs K/L (auto-advance, prep budgets) were **build-only** in sampled rollouts (8/8 build at steps 20/40), with prompts stuck at **round=1** and prep remaining > 0. This suggests rollout_steps was too short to reach reward-informative “last prep action before wave” states. M/N addressed this by pushing rollout_steps=9 and reducing build-slot explosion.
- Runs M/N (round ~4–5, prep remaining mostly 1) started with mixed actions but **collapsed to start_round-only by step ~40**, indicating the rubric still only credits round simulation.
- Run O (credit fix + random policy) still **collapsed to start_round-only by step ~40**; reward/mean last ~132.28 and rollouts showed start_round dominance (steps 40+).
- Run P (credit fix + bootstrap) **collapsed to a single action type** (build-only early, upgrade-only mid) and ended with negative reward/mean (~-5.04), suggesting prompts were too late/hard for single-turn actions.
- Runs Q/R target decision-relevant prompts via `dataset.policy=noop_then_start` (round ~4–5, prep remaining=1); R additionally gates `start_round` to the last prep action to remove the safe-action attractor.
- Run Q (v0.2.7) collapsed to **start_round-only** by step 40 (action mix: step 0 build-only, steps 40/70 start_round-only). Reward/mean fell from ~114.47 (steps 0–3 avg) to ~21.62 (steps 70+ avg); last reward/mean ~21.74.
- Run R (v0.2.7) avoided start_round but stayed **build-only** across steps 0/40/70. Reward/mean remained high: ~112.92 (steps 0–3 avg), ~93.70 (mid), ~121.96 (steps 70+ avg); last reward/mean ~132.18.
- In sampled rollouts (steps 0/40/70), both Q/R prompts were consistently `prep_actions_remaining=1` and `round=5` (with `last_round.round=4`), indicating the rollout targeting is working but action diversity remains limited.
- Run S (v0.2.10) started with a **build/upgrade mix** (step 0: upgrade=5, build=3) but collapsed to **build-only** by step 40/70. Reward/mean stayed high (min ~103.29, max ~139.40, last ~136.40) with `_format_reward=1.0`.
- Run T (v0.2.10, cash-scarce) collapsed to **upgrade-only** across steps 0/40/70. Reward/mean was lower (min ~12.90, max/last ~56.40) with `_format_reward=1.0`.
- Run U (v0.2.11) logged **dominance diagnostic** showing upgrades were optimal in many prompts (best_by_type: upgrade=361, build=73, start_round=24, sell=182; build_vs_upgrade: build=73, upgrade=49). Despite this, rollouts still **collapsed to start_round** by step 40/70 (step 0: upgrade=5, start_round=3; step 40/70: start_round=8). Reward/mean min ~119.81, max ~351.90, last ~227.65; `_format_reward=1.0`, errors 0.
- Run V (v0.2.11, macro-round) showed **short episodes** (`metrics/num_turns` mean ~2.0). Rollouts at steps 0/40 produced **empty plans** (0 actions), while step 70 produced **2-action plans** (build+upgrade). Reward/mean min ~-422.90, max ~1367.19, last ~284.60; macro reward min ~-423.40, max ~1366.69, last ~284.10; format reward ranged -1..1 (last 1.0). One trajectory showed a **round jump to 12 after a single plan** with lives <= 0, which suggests the macro-round env in this run may still be advancing multiple rounds per plan (pre-fix env build). Treat V as **non-diagnostic** until rerun on the fixed env.
- Run W (v0.2.13, SingleTurn; decision filter disabled) produced **decision-relevant snapshots** (round 15/20, prep_remaining=1, towers present), but reward signal was **format-only** (`reward/mean ≈ 0.5`, `_reward_from_action ≈ 0.0`, `_regret_metric ≈ 0.0`), confirming SingleTurn reward-flat behavior. Treat W as the **final SingleTurn diagnostic**.
- Run X (v0.2.13, macro-round) returned **0 rollout samples** (no prompt uploads), so no action-mix or plan diagnostics were captured; rerun required.
- X note (infra): Prime CLI reported HTTP 500s on completion uploads; likely **payload too large**. Mitigation: lower `sampling.max_tokens` (and/or `dataset.rollouts_per_example`) to reduce completion size before rerun.
- Run X2 (v0.2.13, macro-round rerun) still shows **0 rollout samples**. Logs show repeated HTTP 500s on sample uploads; metrics report very large completion lengths (~25–31k tokens/sample) and `is_truncated≈1`, reinforcing the payload-size hypothesis.
- Run X3 (v0.2.13, macro-round) restarted with reduced payload settings (`max_tokens=64`, `rollouts_per_example=1`, smaller observation caps) but still hit HTTP 500s on sample uploads; no samples captured.
- Run X4 (v0.2.13, macro-round) produced samples but **all completions were truncated** (`is_truncated=1.0`) and **format reward = -1** across rollouts, so plans were invalid and round-jump checks were not possible. Payload size is under control; next retry should increase `max_tokens` modestly (e.g., 48) while keeping prompt caps tight.
- Run X5 (v0.2.13, macro-round) produced samples but **format validity remained low** (only 3/48 valid plans; format reward mostly -1). Treat X5 as **format-invalid**.
- Run X6 (v0.2.13, macro-round) produced **valid plans** (48/48) with 1–2 actions and a build+upgrade mix, but **macro-round invariant still fails**: simulated round delta was **0 in 31/48** samples (delta=1 in 17/48). Most delta=0 samples were **round=15 with max_rounds=15**, which truncates before a +1 increment; remaining failures were driven by invalid actions (`insufficient_cash`, `unknown_tower`). Episodes did not clearly lengthen over training (num_turns/mean ~3.47 early vs ~3.48 late). Reward stayed stable without absurd spikes.
- Next macro-round runs (X7/X8) will enforce **candidate-index plans** and set `max_rounds` above snapshot rounds to validate the +1 round invariant without truncation.
- Runs X7–X10 (candidate-index, max_rounds=20) **failed to upload samples** (HTTP 500) despite smaller batches; metrics show large completion lengths and higher num_turns, so payload size is still too large. Likely driver: **longer episodes from max_rounds=20**; set `max_rounds=16` and re-run after publishing the choose-index env to reduce turn count and payload size.
- Run X11 (v0.2.14, max_rounds=16, max_tokens=64) produced samples with **valid plans** and no truncation, but **rounds did not advance** in trajectories (round delta = 0 across all adjacent turns; e.g., round 15 → 15). Plans were always length 2 and **upgrade‑dominant**; `choose_out_of_range` appeared mid/late. Reward/mean was stable (min ~589.7, max ~1496.1, last ~1171.2). **Not successful** against macro-round criteria.
- Run X12 (v0.2.14, max_rounds=16, max_tokens=96) showed the same **round‑stall** pattern (delta 0 across turns), fixed plan length (2), and upgrade‑heavy actions with growing `choose_out_of_range`. Reward/mean stable (min ~595.9, max ~1564.2, last ~1306.9). **Not successful** against macro-round criteria.
- Run X17 (v0.2.18, max_rounds=16, max_tokens=64) **passed round‑delta checks** when parsing all turns (delta_round=1 after turn 1 across steps 0/10/20/30/40/50). Plan length remained 2, and action mix was **upgrade‑dominant** (e.g., step 50: upgrade=86, build=9) matching a heavily upgrade‑skewed candidate pool (step 50: upgrade=598 vs build=54). Reward/mean min ~871.91, max/last ~1524.57; format reward dipped to 0.875 early but ended 1.0.
- Run X18 (v0.2.18, max_rounds=16, max_tokens=96) **passed round‑delta checks** when parsing all turns (delta_round=1 after turn 1 across steps 0/10/20/30/40/50). Plan length was mostly 2, action mix stayed **upgrade‑dominant** (e.g., step 50: upgrade=73, build=4) with a candidate pool skew (step 50: upgrade=312 vs build=65). Reward/mean min ~805.71, max ~1591.90, last ~1007.27; format reward dipped to ~0.893 late.
- Both X17/X18: interleaved warnings were present in logs but round deltas were correct; episode length cannot improve with max_rounds=16 (rollouts already reach 16).
- Run X19/X20 (v0.2.18, max_rounds=24) hit HTTP 500s with **no samples**; completion lengths were ~19–20k tokens and `num_turns≈13`, indicating payload size/timeouts. Stopped and replaced with X21/X22 (max_rounds=18).
- Run X21 (v0.2.18, max_rounds=18, max_tokens=96) produced samples **only at step 0**; logs show HTTP 500s after step 10, so no later samples were uploaded. Step 0 passed round‑delta checks; plan length mostly 2; action mix still upgrade‑dominant but with higher build presence (build=23, upgrade=65). Candidate pool skew remained (build=127 vs upgrade=390). Reward/mean min ~1547.40, max ~2038.71, last ~1950.13; format reward dipped to ~0.882 late.
- Run X22 (v0.2.18, max_rounds=18, max_tokens=64) hit HTTP 500s with **no samples**; stopped and replaced with X23 (max_rounds=16, max_tokens=48).
- Run X23 (v0.2.18, max_rounds=16, max_tokens=48) produced samples at steps 0/10/20/30/40/50. Round‑delta checks **passed** across all turns; plan length mostly 2. Action mix improved with build presence across phases (e.g., step 40: build=32, upgrade=56; step 50: build=29, upgrade=49), and candidate balance increased build availability (step 50 candidates: build=115 vs upgrade=315). Reward/mean min ~796.02, max ~1524.70, last ~1473.81; format reward reached 1.0. Episode length still saturates at max_rounds=16, so “longer episodes” cannot be observed yet.
- Run X24 (v0.2.18, interleaved, max_rounds=16, max_tokens=48) completed with samples at steps 0/10/20/30/40/50. Round‑delta checks **passed** across all turns (0 failures). Plan length was almost always 2 (one 0‑action plan at step 30). Action mix stayed **upgrade‑dominant** with some build (aggregate: upgrade=357, build=72, noop=17), matching a candidate pool still skewed toward upgrades (aggregate: upgrade=2163 vs build=377). By round phase: early build 13 vs upgrade 63; mid build 11 vs upgrade 65; late build 48 vs upgrade 229. Reward/mean min ~1008.76, max ~1524.70, last ~1060.16. No truncation or 500s observed.
- Run X25 (v0.2.18, branching, max_rounds=16, max_tokens=48) completed with samples at steps 0/10/20/30/40/50. Round‑delta checks **passed** across all turns (0 failures). Plan length was consistently 2. Action mix showed **higher build presence** vs X24 (aggregate: upgrade=294, build=181, noop=13), aligned with a more build‑balanced candidate pool (aggregate: upgrade=1259 vs build=666). By round phase: early build 42 vs upgrade 53; mid build 46 vs upgrade 53; late build 93 vs upgrade 188. Reward/mean min ~1066.09, max ~1471.19, last ~1237.00. No truncation or 500s observed.
- Run X26d (v0.2.18, branching, max_rounds=16, max_tokens=40) completed with samples at steps 0/10/20/30/40/50. Round‑delta checks **passed** across all turns (0 failures; 0 missing). Plan length almost always 2 (231/232), invalid_plan=0. Action mix showed **build‑heavy early/mid** with late mixed: early build 51 vs upgrade 36; mid build 54 vs upgrade 32; late build 103 vs upgrade 178. Aggregate actions: build=208, upgrade=246, noop=7 (choose_out_of_range=2). Candidate pool aggregate: build=499 vs upgrade=927. Reward/mean min ~860.97, max ~1562.59, last ~1215.25; format reward remained 1.0; truncation 0. No 500s observed. Episode length improvement still **not measurable** at max_rounds=16.
- Run X27c (v0.2.18, branching, max_rounds=16, max_tokens=40) completed with samples at steps 0/10/20/30/40/50. Round‑delta checks **passed** across all turns (0 failures; 0 missing). Plan length mostly 2 (208/224), with a few 1‑action plans (15) and one 0‑action plan; invalid_plan=0. Action mix was **balanced overall** (build=217, upgrade=213, noop=1). By phase: early build 51 vs upgrade 25; mid build 53 vs upgrade 14; late mixed but upgrade‑dominant (upgrade 174 vs build 113). Candidate pool aggregate: build=394 vs upgrade=815. Reward/mean min ~809.27, max ~1572.91, last ~1391.95; format reward min ~0.893, last 1.0; truncation 0; completion_len/mean max ~7236.67, last ~6161.25. All rollouts ended at round 16 (cap), so episode‑length improvement is **not measurable** yet. No 500s observed.
- Run X28 (v0.2.18, max_rounds=18) stopped after HTTP 500 on sample upload at step 1; replaced by X28b.
- Run X28b (v0.2.18, max_rounds=18, batch_size=8) completed with samples logged at steps 0/10/20/30/40/50, but rollouts at steps 20/30 returned **0 samples** (despite logged uploads). Round‑delta checks **passed** across all parsed turns (0 failures; 0 missing). Plan length mostly 2 (213/216) with a few 1‑action plans (3); invalid_plan=0. Action mix was **upgrade‑dominant** (upgrade=341, build=81, noop=7), aligned with an upgrade‑heavy candidate pool (upgrade=813 vs build=229). By phase: early build 22 vs upgrade 31; mid build 12 vs upgrade 43; late build 47 vs upgrade 267. Reward/mean min ~1439.00, max ~2130.05, last ~1749.45; format reward 1.0; truncation 0. Episodes saturated at round 18 (cap), so length improvement is **not measurable**. 500s occurred at steps 21/31 (sample upload failures).
- Run X29 (v0.2.18, max_rounds=18) stopped after HTTP 500 on sample upload at step 1; replaced by X29b.
- Run X29b (v0.2.18, max_rounds=18, batch_size=4) completed with samples at steps 0/10/20/30/40/50. Round‑delta checks **passed** across all parsed turns (0 failures; 0 missing). Plan length mostly 2 (154/156) with a few 1‑action plans (2); invalid_plan=0. Action mix remained **upgrade‑dominant** but with improved build presence (upgrade=192, build=116, noop=2) alongside a less skewed candidate pool (upgrade=366 vs build=190). By phase: early build 17 vs upgrade 18 (near‑balanced), mid build 14 vs upgrade 22, late build 85 vs upgrade 152 (still upgrade‑leaning). Reward/mean min ~1402.25, max ~2276.70, last ~1843.60; format reward 1.0; truncation 0. Episodes saturated at round 18 (cap), so length improvement is **not measurable**. No 500s observed.
- Run X30 (v0.2.18, max_rounds=18, batch_size=4) completed with samples at steps 0/10/20/30/40/50. Round‑delta checks **passed** across all parsed turns (0 failures; 0 missing). Plan length mostly 2 (169/176) with a few 1‑action plans (7); invalid_plan=0. Action mix was **upgrade‑dominant** (upgrade=271, build=72, noop=2) with a heavily upgrade‑skewed candidate pool (upgrade=621 vs build=132). By phase: early build 21 vs upgrade 29; mid build 10 vs upgrade 46; late build 41 vs upgrade 196 — **plan quality failed** (not build‑heavy early; not mixed mid/late). Reward/mean min ~1440.75, max ~2292.70, last ~2043.90; format reward 1.0; truncation 0. Episodes saturated at round 18 (cap), so length improvement is **not measurable**. No 500s observed.
- Run X31 (v0.2.18, max_rounds=18, batch_size=4) completed with samples at steps 0/10/20/30/40/50. Round‑delta checks **passed** across all parsed turns (0 failures; 0 missing). Plan length mostly 2 (165/168) with a few 1‑action plans (3); invalid_plan=0. Action mix remained **upgrade‑dominant** but improved build presence vs X30 (upgrade=217, build=114, noop=2) alongside a less skewed candidate pool (upgrade=439 vs build=193). By phase: early build 22 vs upgrade 25 (near‑balanced), mid build 19 vs upgrade 29, late build 73 vs upgrade 163 — **plan quality still fails** (mid/late upgrade‑leaning). Reward/mean min ~1414.00, max ~2275.20, last ~1831.85; format reward 1.0; truncation 0. Episodes saturated at round 18 (cap), so length improvement is **not measurable**. No 500s observed.
- Run X32 (v0.2.18, max_rounds=18, batch_size=4, aggressive build bias) completed with samples at steps 0/10/20/30/40/50. Round‑delta checks **passed** across all parsed turns (0 failures; 0 missing). Plan length mostly 2 (136/140) with a few 1‑action plans (4); invalid_plan=0. Action mix remained **upgrade‑dominant** (upgrade=184, build=86, noop=6) with a moderately less skewed candidate pool (upgrade=289 vs build=171). By phase: early build 7 vs upgrade 12; mid build 5 vs upgrade 12; late build 74 vs upgrade 160 — **plan quality fails** (early/mid not build‑heavy; late upgrade‑dominant). Reward/mean min ~1442.75, max ~2266.45, last ~1859.35; format reward 1.0; truncation 0. Episodes saturated at round 18 (cap), so length improvement is **not measurable**. No 500s observed.
- Run X33 (v0.2.18, max_rounds=18, batch_size=4, aggressive build bias + stronger safe_explore prior) completed with samples at steps 0/10/20/30/40/50. Round‑delta checks **passed** across all parsed turns (0 failures; 0 missing). Plan length mostly 2 (156/168) with a higher share of 1‑action plans (12); invalid_plan=0. Action mix remained **upgrade‑dominant** (upgrade=218, build=106) with a skewed candidate pool (upgrade=341 vs build=144). By phase: early build 37 vs upgrade 10 (**build‑heavy early**), mid build 21 vs upgrade 16 (**build‑leaning mid**), late build 48 vs upgrade 192 (**late upgrade‑dominant**) — **partial plan quality** (early/mid pass, late fail). Reward/mean min ~1394.00, max ~2262.70, last ~1831.85; format reward 1.0; truncation 0. Episodes saturated at round 18 (cap), so length improvement is **not measurable**. No 500s observed.
- Run X34 (v0.2.18, max_rounds=18, batch_size=4, late‑phase clamp) completed with samples at steps 0/10/20/30/40/50. Round‑delta checks **passed** across all parsed turns (0 failures; 0 missing). Plan length mix: 1‑action 46, 2‑action 130; invalid_plan=0. Action mix was near‑balanced overall (upgrade=168, build=138), but **late phase remains upgrade‑dominant**. By phase: early build 44 vs upgrade 12 (**build‑heavy early**), mid build 35 vs upgrade 9 (**build‑heavy mid**), late build 59 vs upgrade 147 (**late upgrade‑dominant**) — **partial plan quality** (late fail). Candidate pool aggregate: build=137 vs upgrade=204 (noop=176). Reward/mean min ~1409.75, max ~2250.95, last ~1665.55; format reward 1.0; truncation 0. Episodes saturated at round 18 (cap), so length improvement is **not measurable**. No 500s observed.
- Run X35 (v0.2.18, max_rounds=18, batch_size=4, build‑availability boost) completed with samples at steps 0/10/20/30/40/50. Round‑delta checks **passed** across all parsed turns (0 failures; 0 missing). Plan length mostly 2 (160/176) with some 1‑action plans (16); invalid_plan=0. Action mix improved build presence (upgrade=177, build=148, noop=11), but **late phase is still upgrade‑dominant**. By phase: early build 36 vs upgrade 18 (**build‑leaning early**), mid build 31 vs upgrade 17 (**build‑leaning mid**), late build 81 vs upgrade 142 (**late upgrade‑dominant**) — **partial plan quality** (late fail). Candidate pool aggregate: build=239 vs upgrade=341 (noop=176). Reward/mean min ~1443.50, max ~2259.70, last ~1613.55; format reward 1.0; truncation 0. Episodes saturated at round 18 (cap), so length improvement is **not measurable**. No 500s observed.
- Run X36 (v0.2.18, max_rounds=18, batch_size=4, late upgrade‑leaning w/ build floor) completed with samples at steps 0/10/20/30/40/50. Round‑delta checks **passed** across all parsed turns (0 failures; 0 missing). Plan length mostly 2 (160/172) with some 1‑action plans (12); invalid_plan=0. Action mix was **upgrade‑dominant** (upgrade=267, build=64, noop=1) with a highly upgrade‑skewed candidate pool (upgrade=539 vs build=139). By phase: early build 28 vs upgrade 20 (**build‑leaning early**), mid build 14 vs upgrade 30 (**upgrade‑leaning mid**), late build 22 vs upgrade 217 (**late heavily upgrade‑dominant**) — **plan quality fails** (late build presence too low under new “upgrade‑leaning but still build” target). Reward/mean min ~1398.25, max ~2279.95, last ~2073.90; format reward 1.0; truncation 0. Episodes saturated at round 18 (cap), so length improvement is **not measurable**. No 500s observed.
- Run X37 (v0.2.18, max_rounds=18, batch_size=4, build‑leaning baseline with later snapshots [12,16]) completed with samples at steps 0/10/20/30/40/50. Round‑delta checks **passed** across all parsed turns (0 failures; 0 missing). Plan length mostly 2 (114/116) with very few 1‑action plans (2); invalid_plan=0. Action mix was **build‑leaning overall** (build=126, upgrade=96, noop=8) with a less skewed candidate pool (build=281 vs upgrade=365). By phase (note: rounds start at 12, so “early” not observed): mid build 35 vs upgrade 8 (**build‑leaning mid**), late build 91 vs upgrade 88 (**late balanced**) — **baseline for build‑leaning behavior** (retain as fallback). Reward/mean min ~899.90, max ~1912.85, last ~1373.75; format reward 1.0; truncation 0. Episodes saturated at round 18 (cap), so length improvement is **not measurable**. No 500s observed.
- Run X38 (v0.2.18, max_rounds=18, batch_size=4, late upgrade‑leaning w/ build floor, snapshots [12,16]) completed with samples at steps 0/10/20/30/40/50. Round‑delta checks **passed** across all parsed turns (0 failures; 0 missing). Plan length was always 2 (124/124); invalid_plan=0. Action mix was **slightly upgrade‑leaning overall** (upgrade=131, build=113, noop=4) with a moderately upgrade‑skewed candidate pool (upgrade=426 vs build=283). By phase (rounds start at 12): mid build 38 vs upgrade 13 (**build‑leaning mid**), late build 75 vs upgrade 118 (**late upgrade‑leaning with build presence**) — **plan quality passes** under updated late‑phase target. Reward/mean min ~900.15, max ~1874.85, last ~1613.30; format reward 1.0; truncation 0. Episodes saturated at round 18 (cap), so length improvement is **not measurable**. No 500s observed.
- Run X39 (v0.2.18, max_rounds=18, batch_size=4, stronger late upgrade‑leaning, snapshots [12,16]) completed with samples at steps 0/10/20/30/40/50. Round‑delta checks **passed** across all parsed turns (0 failures; 0 missing). Plan length was always 2 (120/120); invalid_plan=0. Action mix was **upgrade‑leaning overall** (upgrade=134, build=97, noop=9) with a more upgrade‑skewed candidate pool (upgrade=504 vs build=282). By phase: mid build 34 vs upgrade 13 (**build‑leaning mid**), late build 63 vs upgrade 121 (**late upgrade‑leaning with reduced build presence**) — **plan quality passes** (build still present late). Reward/mean min ~912.65, max ~1839.60, last ~1380.75; format reward 1.0; truncation 0. Episodes saturated at round 18 (cap), so length improvement is **not measurable**. No 500s observed.
- Run X40 (v0.2.18, max_rounds=18, batch_size=4, late near‑parity, snapshots [12,16]) completed with samples at steps 0/10/20/30/40/50. Round‑delta checks **passed** across all parsed turns (0 failures; 0 missing). Plan length was always 2 (124/124); invalid_plan=0. Action mix was **build‑leaning overall** (build=138, upgrade=104, noop=6) with a near‑balanced candidate pool (build=285 vs upgrade=322). By phase (rounds start at 12): mid build 39 vs upgrade 13 (**build‑leaning mid**), late build 99 vs upgrade 91 (**late slightly build‑leaning**) — **plan quality partial** (late not upgrade‑leaning). Reward/mean min ~904.15, max ~1881.35, last ~932.15; format reward 1.0; truncation 0. Episodes saturated at round 18 (cap), so length improvement is **not measurable**. No 500s observed.
- Run X41 (v0.2.18, max_rounds=18, batch_size=4, late near‑parity, snapshots [12,16]) completed with samples at steps 10/20/30/40/50 (**step 0 had no samples**). Round‑delta checks **passed** across all parsed turns (0 failures; 0 missing). Plan length mostly 2 (103/104) with one 1‑action plan; invalid_plan=0. Action mix was **upgrade‑leaning overall** (upgrade=124, build=83) with an upgrade‑skewed candidate pool (upgrade=350 vs build=214). By phase: mid build 29 vs upgrade 14 (**build‑leaning mid**), late build 54 vs upgrade 110 (**late upgrade‑leaning with build present**) — **plan quality passes** under updated late‑phase target. Reward/mean min ~891.15, max ~1867.10, last ~1192.70; format reward 1.0; truncation 0. Episodes saturated at round 18 (cap), so length improvement is **not measurable**. No 500s observed.
- Run X42 (v0.2.18, max_rounds=18, batch_size=4, late target probe, snapshots [12,16]) completed with samples at steps 0/10/20/30/40/50. Round‑delta checks **passed** across all parsed turns (0 failures; 0 missing). Plan length mostly 2 (122/124) with two 1‑action plans; invalid_plan=0. Action mix was **upgrade‑leaning overall** (upgrade=143, build=102, noop=1) with an upgrade‑skewed candidate pool (upgrade=413 vs build=254). By phase (rounds start at 12): mid build 32 vs upgrade 18 (**build‑leaning mid**), late build 70 vs upgrade 125 (**late upgrade‑leaning with build present**) — **plan quality passes** under the “late upgrade ~10–15% higher” target. Reward/mean min ~910.40, max ~1891.35, last ~1866.35; format reward 1.0; truncation 0. Episodes saturated at round 18 (cap), so length improvement is **not measurable**. No 500s observed.
- Run X43 (v0.2.18, max_rounds=18, batch_size=4, late target probe, snapshots [12,16]) completed with samples at steps 0/10/20/30/40/50. Round‑delta checks **passed** across all parsed turns (0 failures; 0 missing). Plan length was always 2 (132/132); invalid_plan=0. Action mix was **near‑balanced overall** (upgrade=129, build=127, noop=8) with a slightly upgrade‑skewed candidate pool (upgrade=352 vs build=292). By phase: mid build 44 vs upgrade 16 (**build‑leaning mid**), late build 83 vs upgrade 113 (**late upgrade‑leaning with build present**) — **plan quality passes** under the “late upgrade ~10–15% higher” target. Reward/mean min ~896.40, max ~1861.35, last ~1667.55; format reward 1.0; truncation 0. Episodes saturated at round 18 (cap), so length improvement is **not measurable**. No 500s observed.
- Run X44 (v0.2.18, max_rounds=20, batch_size=4, episode‑length probe) completed with samples at steps 0/10/20/30/40/50. Round‑delta checks **passed** across all parsed turns (0 failures; 0 missing). Plan length was always 2 (148/148); invalid_plan=0. Action mix was **upgrade‑leaning overall** (upgrade=166, build=126, noop=4) with an upgrade‑skewed candidate pool (upgrade=407 vs build=296). By phase (rounds start at 12): mid build 21 vs upgrade 7 (**build‑leaning mid**), late build 105 vs upgrade 159 (**late upgrade‑leaning with build present**) — **plan quality passes** under the target. Reward/mean min ~1615.50, max ~2540.70, last ~2344.90; format reward 1.0; truncation 0. Episodes ended at round **20** (cap), so episode length still **not measured beyond cap**. No 500s observed.
- Run X45 (v0.2.18, max_rounds=22, batch_size=4, episode‑length probe) completed with samples at steps 0/10/20/30/40/50. Round‑delta checks **passed** across all parsed turns (0 failures; 0 missing). Plan length was always 2 (220/220); invalid_plan=0. Action mix was **upgrade‑dominant overall** (upgrade=293, build=136, noop=11) with a heavily upgrade‑skewed candidate pool (upgrade=587 vs build=334). By phase: mid build 41 vs upgrade 11 (**build‑leaning mid**), late build 95 vs upgrade 282 (**late strongly upgrade‑dominant**) — **plan quality fails** (late upgrades exceed target; build presence too low). Reward/mean min ~2372.10, max ~3336.05, last ~2583.90; format reward 1.0; truncation 0. Episodes ended at round **22** (cap), so episode length still **not measured beyond cap**. No 500s observed.
- Run X46/X47 (v0.2.18, max_rounds=24/26, batch_size=4) were stopped and deleted after recurring HTTP 500 upload failures; rerun as X46b/X47b with `batch_size=2`.
- Run X46b (v0.2.18, max_rounds=24, batch_size=2, branching) completed with samples at steps 0/10/20/30/40/50. Parsed all rollouts and all turns: 12 samples, plan length always 2 (132/132), invalid_plan=0, choose_out_of_range=0. Action mix was **upgrade‑dominant** with build presence (upgrade=186, build=75, noop=3), and the candidate pool remained upgrade‑skewed (upgrade=353 vs build=181; noop candidates=132). By phase: mid build 17 vs upgrade 7; late build 58 vs upgrade 179 (**late upgrade‑dominant**). Round progression: all non-cap checks passed; the only `delta_round=0` observations occurred at round 24 cap (12/120 checks). Reward/mean min ~3055.2, max ~4156.9, last ~3558.8; format reward 1.0; truncation 0; completion_len/mean min ~9716.5, max ~15088.0, last ~12207.5. No upload 500s; logs showed transient server sync/model-query connection errors that self-recovered.
- Run X47b (v0.2.18, max_rounds=26, batch_size=2, branching) completed with samples at steps 0/10/20/30/40/50. Parsed all rollouts and all turns: 12 samples, plan length always 2 (148/148), invalid_plan=0, choose_out_of_range=0. Action mix stayed **more upgrade‑dominant** than X46b (upgrade=214, build=69, noop=13), with an upgrade‑skewed candidate pool (upgrade=391 vs build=198; noop candidates=148). By phase: mid build 9 vs upgrade 6; late build 60 vs upgrade 208 (**late strongly upgrade‑dominant**). Round progression: all non-cap checks passed; the only `delta_round=0` observations occurred at round 26 cap (12/136 checks). Reward/mean min ~2810.7, max ~4936.0, last ~4844.5; format reward 1.0; truncation 0; completion_len/mean min ~9596.0, max/last ~18086.0. No upload 500s; metrics recorded one transient model connection error at step 33 (`error/mean=0.5`) that self-recovered.
- Run X48 (v0.2.18, max_rounds=18, batch_size=4, branching) completed with samples at steps 0/10/20/30/40/50. Parsed all rollouts and all turns: 24 samples, plan length always 2 (124/124), invalid_plan=0, choose_out_of_range=2. Action mix was near parity overall (upgrade=126, build=119, noop=1) with a moderately upgrade‑skewed candidate pool (upgrade=333 vs build=270; noop candidates=124). By phase: mid build 61 vs upgrade 43 (**build‑leaning mid**), late build 58 vs upgrade 83 (**late upgrade‑leaning**, ~43% more upgrades than builds). Round progression: all non-cap checks passed; the only `delta_round=0` observations occurred at round 18 cap (24/100 checks). Reward/mean min ~911.9, max ~1881.35, last ~1161.2; format reward 1.0; truncation 0; completion_len/mean min ~2679.25, max ~7687.0, last ~4003.5. No upload 500s observed.
- Run X49 (v0.2.18, max_rounds=28, batch_size=2, branching) completed with samples at steps 0/10/20/30/50 (step 40 sample upload failed). Parsed all available rollouts and all turns: 10 samples, plan length always 2 (146/146), invalid_plan=0, choose_out_of_range=0. Action mix became strongly upgrade‑dominant (upgrade=238, build=54) with an upgrade‑skewed candidate pool (upgrade=380 vs build=190; noop candidates=146). By phase: mid build 18 vs upgrade 14 (**build‑leaning mid**), late build 36 vs upgrade 224 (**late heavily upgrade‑dominant**). Round progression: all non-cap checks passed; the only `delta_round=0` observations occurred at round 28 cap (10/136 checks). Reward/mean min ~4715.4, max ~5818.6, last ~4825.9; format reward 1.0; truncation 0; completion_len/mean min ~14570.5, max ~20520.5, last ~15399.0. Logs show an intermittent sample-upload failure at step 40 (`HTTP 500 Internal Server Error`), after which training continued to completion.
- Run X50 (v0.2.18, max_rounds=18, batch_size=4, branching) completed with samples at steps 0/10/20/30/40/50. Parsed all rollouts and all turns: 24 samples, plan length always 2 (124/124), invalid_plan=0, choose_out_of_range=0. Action mix was near parity overall (build=123, upgrade=118, noop=7) with a moderately upgrade-skewed candidate pool (build=260 vs upgrade=324; noop candidates=124). By phase: mid build 64 vs upgrade 39 (**build-leaning mid**), late build 59 vs upgrade 79 (**late upgrade-leaning**, ~34% more upgrades than builds). Round progression: all non-cap checks passed; the only `delta_round=0` observations occurred at round 18 cap (24/100 checks). Reward/mean min ~924.4, max ~1857.85, last ~1404.75; format reward 1.0; truncation 0; completion_len/mean min ~2773.0, max ~7541.0, last ~5169.0. No upload 500s observed.
- Run X51 (v0.2.18, max_rounds=30, batch_size=2, branching) completed **without retrievable rollout samples** (steps 0/10/20/30/40/50 all returned 0 samples). Logs show repeated sample-upload failures (`HTTP 500 Internal Server Error`) at each sample checkpoint while training continued to completion. Metrics remained well-formed (reward/mean min ~5693.5, max ~6836.7, last ~6621.7; format reward 1.0; truncation 0), but completion payloads were large (completion_len/mean min ~16864.5, max ~22802.0, last ~21446.5; num_turns/mean up to 19), so behavioral analysis for X51 is **not possible** from rollouts.
- Run X52 (v0.2.18, max_rounds=18, batch_size=4, branching) completed with samples at steps 0/10/20/30/40/50. Parsed all rollouts and all turns: 24 samples, plan length mostly 2 (127/128) with one 1-action plan; invalid_plan=0, choose_out_of_range=0. Action mix was build-leaning overall (build=140, upgrade=109, noop=6) with candidate availability still upgrade-skewed (build=277 vs upgrade=328; noop candidates=128). By phase: mid build 74 vs upgrade 33 (**build-leaning mid**), late build 66 vs upgrade 76 (**late upgrade-leaning**, ~15% more upgrades than builds). Round progression: all non-cap checks passed; the only `delta_round=0` observations occurred at round 18 cap (24/104 checks). Reward/mean min ~901.9, max ~1895.85, last ~901.9; format reward min ~0.929, last 1.0; truncation 0; completion_len/mean min ~2594.0, max ~7562.5, last ~2719.75. No upload 500s; one transient server sync error at run end.
- Run X53 (v0.2.18, max_rounds=30, batch_size=2, stricter observation caps) completed with samples at steps 10/40/50 only (step samples: 2/2/2). Steps 0/20/30 logged sample upload attempts but then hit `HTTP 500 Internal Server Error`, so those rollouts are unavailable. Parsed all available rollouts and all turns: 6 samples, plan length mostly 2 (100/102) with two 1-action plans; invalid_plan=0, choose_out_of_range=0. Action mix was strongly upgrade-dominant (upgrade=171, build=14, noop=17). By phase: mid build 5 vs upgrade 15, late build 9 vs upgrade 156 with high noop (15). Candidate availability in parsed turns was heavily skewed late (late candidates: build=30, upgrade=234, noop=90), indicating build-opportunity starvation under the strict payload caps. Round progression: all non-cap checks passed; the only `delta_round=0` observations occurred at round 30 cap (6/96 checks). Reward/mean min ~4768.9, max ~6793.2, last ~6153.6; format reward 1.0; truncation 0; completion_len/mean min ~13314.0, max ~20188.5, last ~17114.5.
- Run X54 (v0.2.18, max_rounds=18, batch_size=4, branching) completed with samples at steps 0/10/20/30/40/50. Parsed all rollouts and all turns: 24 samples, plan length always 2 (124/124), invalid_plan=0, choose_out_of_range=0. Action mix was build-leaning overall (build=147, upgrade=100, noop=1) while candidate availability was near-balanced with slight upgrade skew (build=275 vs upgrade=310; noop candidates=124). By phase (rounds start at 12): mid build 41 vs upgrade 11 (**build-heavy mid**), late build 106 vs upgrade 89 (**late build-leaning**) - **plan quality fails** the late adaptive target (should be upgrade-leaning with build present). Round progression: all post-turn checks passed (`delta_round == 1` for 100/100, 0 missing, 0 pre-cap failures). Reward/mean min ~911.4, max ~1896.85, last ~1160.7; format reward 1.0; truncation 0; completion_len/mean min ~2700.75, max ~7765.0, last ~3989.0. No upload 500s observed. Episodes saturated at round 18 cap, so episode length remains **not measurable beyond cap** in this run.
- Run X55 (v0.2.18, max_rounds=30, batch_size=2, branching) completed with partial retrievable samples at steps 10/20/40 only (step samples: 2/2/2). Logs show sample-upload `HTTP 500 Internal Server Error` warnings around steps 0/30/50, so those rollout checkpoints are missing. Parsed all available rollouts and all turns: 6 samples, plan length always 2 (90/90), invalid_plan=0, choose_out_of_range=0. Action mix was strongly upgrade-dominant (upgrade=136, build=44), and candidate availability was similarly skewed (upgrade=246, build=79, noop=90). By phase (all sampled turns are late due snapshots at rounds 12/16): late build 44 vs upgrade 136 (~209% upgrade lead; build share ~24%) - **plan quality fails** adaptive late target (upgrade lead too large despite some build presence). Round progression: all post-turn checks passed (`delta_round == 1` for 84/84, 0 missing, 0 pre-cap failures). Reward/mean min ~5622.0, max ~6841.2, last ~6144.6; format reward 1.0; truncation 0; completion_len/mean min ~16133.0, max ~22811.0, last ~18475.5. Parsed rollouts all reached round 30 cap, so episode length remains **cap-limited/inconclusive beyond cap**, but X55 does show horizon execution can reach 30 under current settings when sample uploads succeed.
- Run X56 (v0.2.18, max_rounds=18, batch_size=4, branching) completed with samples at steps 0/10/20/30/40/50. Parsed all rollouts and all turns: 24 samples, plan length mostly 2 (102/104) with two 1-action plans; invalid_plan=0, choose_out_of_range=0. Action mix was build-leaning overall (build=123, upgrade=83) and candidate availability was near-balanced with mild upgrade skew (build=247 vs upgrade=271; noop candidates=104). By phase (rounds start at 12): mid build 23 vs upgrade 9 (**build-heavy mid**), late build 100 vs upgrade 74 (**late build-leaning**) - **plan quality fails** the adaptive late target (late should be upgrade-leaning with build presence). Round progression: all post-turn checks passed (`delta_round == 1` for 80/80, 0 missing, 0 pre-cap failures). Reward/mean min ~895.9, max ~1881.35, last ~1418.75; format reward 1.0; truncation 0; completion_len/mean min ~2649.25, max ~7862.25, last ~5279.25. No upload 500s observed. Episodes saturated at round 18 cap, so episode length remains **not measurable beyond cap** in this run.
- Run X57 (v0.2.18, max_rounds=30, batch_size=1, branching) completed with samples at steps 0/10/20/30/40/50 (step samples: 1/1/1/1/1/1). Parsed all rollouts and all turns: 6 samples, plan length always 2 (90/90); invalid_plan=0, choose_out_of_range=0. Action mix was upgrade-dominant (upgrade=130, build=35, noop=15), with candidate availability also skewed to upgrades (upgrade=260, build=98, noop=90). By phase (snapshots at rounds 14/18, so parsed turns are effectively late): late build 35 vs upgrade 130 (~271% upgrade lead; build share ~21%) - **plan quality fails** adaptive late target (upgrade lead too large; build share below floor). Round progression: all post-turn checks passed (`delta_round == 1` for 84/84, 0 missing, 0 pre-cap failures). Reward/mean min ~4994.9, max ~6544.1, last ~6210.1; format reward 1.0; truncation 0; completion_len/mean min ~13294.0, max ~20503.0, last ~18510.0. No sample-upload 500s and no missing sample steps. Parsed rollouts reached round 30 cap, so episode length beyond cap remains **inconclusive**, but upload reliability is improved versus prior max_rounds=30 runs.
- Run X58 (v0.2.18, max_rounds=18, batch_size=4, branching) completed with samples at steps 0/10/20/30/40/50. Parsed all rollouts and all turns: 24 samples, plan length mostly 2 (126/128) with two 1-action plans; invalid_plan=0, choose_out_of_range=0. Action mix was slightly **upgrade-leaning overall** (upgrade=137, build=113, noop=4) with a more upgrade-skewed candidate pool than X56 (upgrade=378 vs build=256; noop candidates=128). By phase (rounds start at 12): mid build 34 vs upgrade 21 (**build-leaning mid**), late build 79 vs upgrade 116 (**late upgrade-leaning with build presence**, ~47% upgrade lead) - **plan quality pass (partial)** for late target direction but still above preferred 15-25% lead band. Round progression: all post-turn checks passed (`delta_round == 1` for 104/104, 0 missing, 0 pre-cap failures). Reward/mean min ~889.9, max ~1887.6, last ~1859.6; format reward min ~0.571 (recovered to 1.0 by end), truncation 0; completion_len/mean min ~2762.0, max ~7856.75, last ~7458.75. No upload 500s observed. Episodes saturated at round 18 cap, so episode length remains **not measurable beyond cap** in this run.
- Run X59 (v0.2.18, max_rounds=32, batch_size=1, branching) completed with samples at steps 0/10/20/30/40/50 (step samples: 1/1/1/1/1/1). Parsed all rollouts and all turns: 6 samples, plan length always 2 (106/106); invalid_plan=0, choose_out_of_range=0. Action mix remained strongly upgrade-dominant (upgrade=175, build=37) with a heavily upgrade-skewed candidate pool (upgrade=298 vs build=70; noop candidates=106). By phase (snapshots at rounds 14/18, parsed turns effectively late): late build 37 vs upgrade 175 (~373% upgrade lead; build share ~17%) - **plan quality fails** adaptive late target (upgrade lead too large; build floor missed). Round progression: all post-turn checks passed (`delta_round == 1` for 100/100, 0 missing, 0 pre-cap failures). Reward/mean min ~5892.5, max ~7395.7, last ~6150.5; format reward 1.0; truncation 0; completion_len/mean min ~16099.0, max ~23059.0, last ~16320.0. No sample-upload 500s and no missing sample steps. Parsed rollouts reached round 32 cap, so episode length beyond cap remains **inconclusive**, but this extends stable capped-horizon execution and sample reliability versus earlier runs.
- Run X60 (v0.2.18, max_rounds=18, batch_size=4, branching) completed with samples at steps 0/10/20/30/40/50. Parsed all rollouts and all turns: 24 samples, plan length mostly 2 (110/112) with two 1-action plans; invalid_plan=0, choose_out_of_range=0. Action mix remained **upgrade-leaning overall** (upgrade=121, build=99, noop=2) with an upgrade-skewed candidate pool (upgrade=365 vs build=231; noop candidates=112). By phase (rounds start at 12): mid build 26 vs upgrade 12 (**build-leaning mid**), late build 73 vs upgrade 109 (**late upgrade-leaning with build presence**, ~49% upgrade lead) - **plan quality pass (partial)** for late target direction but still above preferred lead band. Round progression: all post-turn checks passed (`delta_round == 1` for 88/88, 0 missing, 0 pre-cap failures). Reward/mean min ~902.65, max ~1902.6, last ~1635.05; format reward 1.0; truncation 0; completion_len/mean min ~2820.0, max ~7812.75, last ~6323.75. No sample-upload 500s observed. Episodes saturated at round 18 cap, so episode length remains **not measurable beyond cap** in this run.
- Run X61 (v0.2.18, max_rounds=34, batch_size=1, branching) completed with samples at steps 0/10/20/30/40/50 (step samples: 1/1/1/1/1/1). Parsed all rollouts and all turns: 6 samples, plan length always 2 (114/114); invalid_plan=0, choose_out_of_range=0. Action mix remained strongly upgrade-dominant (upgrade=191, build=37) with a heavily upgrade-skewed candidate pool (upgrade=322 vs build=70; noop candidates=114). By phase (snapshots at rounds 14/18, parsed turns effectively late): late build 37 vs upgrade 191 (~416% upgrade lead; build share ~16%) - **plan quality fails** adaptive late target (upgrade lead too large; build floor missed). Round progression: all post-turn checks passed (`delta_round == 1` for 108/108, 0 missing, 0 pre-cap failures). Reward/mean min ~6811.1, max ~8370.3, last ~6886.1; format reward 1.0; truncation 0; completion_len/mean min ~17632.0, max ~25582.0, last ~18405.0. No sample-upload 500s and no missing sample steps. Parsed rollouts reached round 34 cap, so episode length beyond cap remains **inconclusive**, but reliability-first horizon execution remains stable at higher cap.
- Run X62 (v0.2.18, max_rounds=18, batch_size=4, branching) completed with samples at steps 0/10/20/30/40/50. Parsed all rollouts and all turns: 24 samples, plan length mostly 2 (109/112) with three 1-action plans; invalid_plan=0, choose_out_of_range=0. Action mix was slightly **build-leaning overall** (build=116, upgrade=105) with an upgrade-skewed candidate pool (upgrade=356 vs build=239; noop candidates=112). By phase (rounds start at 12): mid build 28 vs upgrade 11 (**build-leaning mid**), late build 88 vs upgrade 94 (**late upgrade-leaning with build presence**, ~7% upgrade lead) - **plan quality partial** (late direction is correct but below the preferred 15-25% lead band). Round progression: all non-cap checks passed (`delta_round == 1` for 88/88, 0 missing, 0 pre-cap failures); cap-bound observations were `delta_round=0` at round 18 (24/112 checks). Reward/mean min ~881.65, max ~1882.10, last ~1352.25; format reward 1.0; truncation 0; completion_len/mean min ~2613.5, max ~7757.0, last ~5211.25. No sample-upload 500s observed. Episodes saturated at round 18 cap, so episode length remains **not measurable beyond cap** in this run.
- Run X63 (v0.2.18, max_rounds=36, batch_size=1, branching) completed with samples at steps 0/10/30/40/50 (**step 20 had 0 samples**). Parsed all available rollouts and all turns: 5 samples, plan length always 2 (107/107); invalid_plan=0, choose_out_of_range=0. Action mix was strongly **upgrade-dominant** (upgrade=181, build=29, noop=4) with a heavily upgrade-skewed candidate pool (upgrade=311 vs build=77; noop candidates=107). By phase (snapshots at rounds 14/18, parsed turns effectively late): late build 29 vs upgrade 181 (~524% upgrade lead; build share ~14%) - **plan quality fails** adaptive late target (upgrade lead too large; build floor missed). Round progression: all non-cap checks passed (`delta_round == 1` for 102/102, 0 missing, 0 pre-cap failures); cap-bound observations were `delta_round=0` at round 36 (5/107 checks). Reward/mean min ~7898.7, max ~9573.9, last ~9151.9; format reward 1.0; truncation 0; completion_len/mean min ~20616.0, max ~29027.0, last ~25513.0. Logs show one sample-upload `HTTP 500 Internal Server Error` at step 20, matching missing step-20 rollouts. Parsed rollouts reached round 36 cap, so episode length beyond cap remains **inconclusive**, but horizon lower-bound execution extends to >=36.
- Run X64 (v0.2.18, max_rounds=18, batch_size=4, branching) completed with samples at steps 0/10/20/30/40/50. Parsed all rollouts and all turns: 24 samples, plan length always 2 (100/100); invalid_plan=0, choose_out_of_range=0. Action mix was near-balanced with mild upgrade lead (upgrade=104, build=92, noop=4) and a moderately upgrade-skewed candidate pool (upgrade=370 vs build=235; noop candidates=100). By phase (snapshots at rounds 12/16): mid build 19 vs upgrade 9 (**build-leaning mid**), late build 73 vs upgrade 95 (**late upgrade-leaning with build presence**, ~30% upgrade lead) - **plan quality pass (partial)** for target direction, but still above the preferred 15-25% lead band. Round progression: all non-cap checks passed (`delta_round == 1` for 52/52, 0 missing, 0 pre-cap failures); cap-bound observations were `delta_round=0` at round 18 (24/48 checks). Reward/mean min ~915.9, max ~1861.35, last ~1387.75; format reward 1.0; truncation 0; completion_len/mean min ~2917.0, max ~7919.75, last ~5437.0. No sample-upload 500s observed.
- Run X65 (v0.2.18, max_rounds=36, batch_size=1, branching) completed with samples at steps 0/10/20/30/40/50 (step samples: 1/1/1/1/1/1). Parsed all rollouts and all turns: 6 samples, plan length always 2 (122/122); invalid_plan=0, choose_out_of_range=0. Action mix was strongly upgrade-dominant (upgrade=207, build=37) with a heavily upgrade-skewed candidate pool (upgrade=352 vs build=67; noop candidates=122). By phase (snapshots at rounds 14/18, parsed turns effectively late): late build 37 vs upgrade 207 (~459% upgrade lead; build share ~15%) - **plan quality fails** adaptive late target (upgrade lead too large; build floor missed). Round progression: all non-cap checks passed (`delta_round == 1` for 110/110, 0 missing, 0 pre-cap failures); cap-bound observations were `delta_round=0` at round 36 (6/12 checks). Reward/mean min ~7851.7, max ~9556.9, last ~9058.9; format reward 1.0; truncation 0; completion_len/mean min ~19098.0, max ~26976.0, last ~24804.0. No sample-upload 500s observed. Parsed rollouts reached round 36 cap with full sample checkpoints, so horizon reliability improved, but beyond-cap episode length remains **inconclusive**.
- Run X66 (v0.2.19, max_rounds=18, batch_size=4, branching) completed with samples at steps 0/10/20/30/40/50. Parsed all rollouts and all turns: 24 samples, plan length mostly 2 (114/116) with two 1-action plans; invalid_plan=0, choose_out_of_range=0. Action mix was near-balanced with mild upgrade lead (upgrade=118, build=112) and a moderately upgrade-skewed candidate pool (upgrade=370 vs build=255; noop candidates=116). By phase (snapshots at rounds 12/16): mid build 25 vs upgrade 18 (**build-leaning mid**), late build 87 vs upgrade 100 (**late upgrade-leaning with build presence**, ~15% upgrade lead) - **plan quality pass** (meets the lower bound of the preferred 15-25% late upgrade-lead band). Round progression: all non-cap checks passed (`delta_round == 1` for 68/68, 0 missing, 0 pre-cap failures); cap-bound observations were `delta_round=0` at round 18 (24/48 checks). Reward/mean min ~903.4, max ~1884.35, last ~1848.35; format reward 1.0; truncation 0; completion_len/mean min ~2740.5, max ~7823.75, last ~7531.25. No sample-upload 500s observed.
- Run X67 (v0.2.19, max_rounds=38, batch_size=1, branching) completed with samples at steps 10/30/50 only (**steps 0/20/40 sample uploads failed with HTTP 500**). Parsed all available rollouts and all turns: 3 samples, plan length always 2 (63/63); invalid_plan=0, choose_out_of_range=0. Action mix was strongly upgrade-dominant (upgrade=106, build=20) with a heavily upgrade-skewed candidate pool (upgrade=179 vs build=32; noop candidates=63). By phase (snapshots at rounds 14/18, parsed turns effectively late): late build 20 vs upgrade 106 (~430% upgrade lead; build share ~16%) - **plan quality fails** adaptive late target (upgrade lead too large; build floor missed). Round progression: all non-cap checks passed on available rollouts (`delta_round == 1` for 57/57, 0 missing, 0 pre-cap failures); cap-bound observations were `delta_round=0` at round 38 (3/6 checks). Reward/mean min ~5699.4, max ~10215.5, last ~6734.2; format reward 1.0; truncation 0; completion_len/mean min ~21820.0, max ~29407.0, last ~29371.0. Parsed rollouts reached round 38 cap, so horizon lower-bound execution extends to >=38, but beyond-cap episode length remains **inconclusive** and sample reliability regressed vs X65.
- Run X68 (v0.2.19, max_rounds=18, batch_size=4, branching) completed with samples at steps 0/10/20/30/40/50 (step samples: 4/4/4/4/4/4). Parsed all rollouts and all turns: 24 samples, plan length mostly 2 (121/124) with three 1-action plans; invalid_plan=0, choose_out_of_range=0. Action mix was near-balanced (upgrade=123, build=120, noop=2) with an upgrade-skewed candidate pool (upgrade=377 vs build=256; noop candidates=124). By phase (snapshots at rounds 12/16): mid build 37 vs upgrade 14 (**build-leaning mid**), late build 83 vs upgrade 109 (**late upgrade-leaning with build presence**, ~31% upgrade lead) - **plan quality partial** (correct direction, but above the preferred 15-25% lead band). Round progression: all non-cap checks passed (`delta_round == 1` for 76/76, 0 missing, 0 pre-cap failures); cap-bound observations at round 18 were split between `delta_round=1` and `delta_round=0` with cap-zero at 24/48 checks. Reward/mean min ~910.4, max ~1890.6, last ~1407.5; format reward 1.0; truncation 0; completion_len/mean min ~2686.75, max ~7747.75, last ~5316.0. No sample-upload 500s observed.
- Run X69 (v0.2.19, max_rounds=38, batch_size=1, branching) completed with samples at steps 10/20/30/40/50 (**step 0 sample upload failed with HTTP 500 after retries**). Parsed all available rollouts and all turns: 5 samples, plan length always 2 (117/117); invalid_plan=0, choose_out_of_range=0. Action mix was strongly upgrade-dominant (upgrade=215, build=19) with a heavily upgrade-skewed candidate pool (upgrade=341 vs build=31; noop candidates=117). By phase (snapshots at rounds 14/18, parsed turns effectively late-only): late build 19 vs upgrade 215 (~1032% upgrade lead; build share ~8%) - **plan quality fails** adaptive late target (upgrade lead too large; build floor missed). Round progression: all non-cap checks passed on available rollouts (`delta_round == 1` for 107/107, 0 missing, 0 pre-cap failures); cap-bound observations were `delta_round=0` at round 38 (5/10 checks). Reward/mean min ~4166.3, max ~7956.5, last ~6618.8; format reward 1.0; truncation 0; completion_len/mean min ~20471.0, max ~26131.0, last ~20759.0. Parsed rollouts reached round 38 cap, so horizon lower-bound execution remains >=38, but beyond-cap episode length is still **inconclusive** and sample reliability is **partial**.
- Run X70 (v0.2.19, max_rounds=18, batch_size=4, branching) completed with samples at steps 0/10/20/30/40/50 (step samples: 4/4/4/4/4/4). Parsed all rollouts and all turns: 24 samples, plan length mostly 2 (113/116) with three 1-action plans; invalid_plan=0, choose_out_of_range=0. Action mix was near-balanced overall (build=116, upgrade=112, noop=1) with an upgrade-skewed candidate pool (upgrade=354 vs build=242; noop candidates=116). By phase (snapshots at rounds 12/16): mid build 34 vs upgrade 10 (**build-leaning mid**), late build 82 vs upgrade 102 (**late upgrade-leaning with build presence**, ~24% upgrade lead) - **plan quality pass** (near upper bound of preferred 15-25% band). Round progression: all non-cap checks passed (`delta_round == 1` for 68/68, 0 missing, 0 pre-cap failures); cap-bound observations at round 18 were split (`delta_round=0` in 24/48 checks). Reward/mean min ~902.15, max ~1883.35, last ~1137.70; format reward 1.0; truncation 0; completion_len/mean min ~2727.25, max ~7917.75, last ~3983.25. No sample-upload 500s observed.
- Run X71 (v0.2.19, max_rounds=38, batch_size=1, branching) completed with samples at steps 0/10/20/30/40/50 (step samples: 1/1/1/1/1/1) and no sample-upload 500s, but policy outputs were persistently invalid. Parsed all rollouts and all turns: 6 samples, assistant turns=103, **format-invalid plans=103/103**, plan-length histogram=`invalid` only, and parsed chosen action mix was empty. Metrics confirm persistent generation failure: `is_truncated/mean=1.0` throughout, `_macro_round_format_reward=-1.0` throughout, reward/mean stayed negative (min/last -25.8, max -10.4), completion_len/mean remained very large (~8.4k to ~23.1k), and num_turns rose to 23. Round progression degraded (`delta_round` non-cap pass/fail = 95/4). Parsed rollouts reached round 38 cap in 2/6 samples only. **Fail** for behavior and horizon inference; treat X71 as configuration-invalid due over-tight generation budget (`max_tokens=32`) under this prompt regime.
- Run X72 (v0.2.19, max_rounds=18, batch_size=4, branching) completed with samples at steps 0/10/20/30/40/50 (step samples: 4/4/4/4/4/4). Parsed all rollouts and all turns: 24 samples, plan length mostly 2 (119/120) with one 1-action plan; invalid_plan=0, choose_out_of_range=0. Action mix was slightly build-leaning overall (build=124, upgrade=113, noop=2) with an upgrade-skewed candidate pool (upgrade=374 vs build=251; noop candidates=120). By phase (snapshots at rounds 12/16): mid build 40 vs upgrade 8 (**build-leaning mid**), late build 84 vs upgrade 105 (**late upgrade-leaning with build presence**, ~25% upgrade lead) - **plan quality pass** (upper bound of preferred 15-25% band). Round progression: all non-cap checks passed (`delta_round == 1` for 72/72, 0 missing, 0 pre-cap failures); cap-bound observations at round 18 were split (`delta_round=0` in 24/48 checks). Reward/mean min ~776.50, max ~1883.35, last ~1159.45; format reward 1.0; truncation 0; completion_len/mean min ~2102.75, max ~7659.50, last ~3877.00. No sample-upload 500s observed; one transient metric error spike (`error/mean=0.5` at step 8) self-recovered.
- Run X73 (v0.2.19, max_rounds=38, batch_size=1, branching) completed with samples at steps 0/10/20/30/40/50 (step samples: 1/1/1/1/1/1). Parsed all rollouts and all turns: 6 samples, plan length always 2 (126/126), invalid_plan=0, choose_out_of_range=0. Action mix was strongly upgrade-dominant (upgrade=227, build=25) with upgrade-heavy candidate pool (upgrade=248 vs build=70; noop candidates=126). By phase (snapshots at rounds 16/20, effectively late-only): late build 25 vs upgrade 227 (~808% upgrade lead; build share ~10%) - **plan quality fail** adaptive late target (upgrade lead too large; build floor missed). Round progression: all non-cap checks passed (`delta_round == 1` for 114/114, 0 missing, 0 pre-cap failures); cap-bound observations at round 38 were split (`delta_round=0` in 6/12 checks). Reward/mean min ~627.10, max ~9363.90, last ~4142.00; format reward 1.0; truncation 0; completion_len/mean min ~1077.0, max ~21084.0, last ~20766.0; num_turns max/last 23. No sample-upload 500s observed; one transient server-sync/model-query connection error early in run self-recovered.
- Run X74 (v0.2.19, max_rounds=18, batch_size=4, branching) completed with samples at steps 0/10/20/30/40/50 (step samples: 4/4/2/4/4/4). Parsed all retrieved rollouts and all turns: 22 samples, plan length always 2 (102/102), invalid_plan=0, choose_out_of_range=0. Action mix was near parity overall (build=102, upgrade=100, noop=2), while candidate availability stayed upgrade-skewed (build=232 vs upgrade=322; noop candidates=102). By phase (snapshots at rounds 12/16): mid build 30 vs upgrade 6 (**build-leaning mid**), late build 72 vs upgrade 94 (**late upgrade-leaning with build presence**, ~31% upgrade lead) - **plan quality partial** (direction is correct, but above preferred 15-25% band). Round progression: all non-cap checks passed (`delta_round == 1` for 58/58, 0 missing, 0 pre-cap failures); cap-bound observations at round 18 were split (`delta_round=0` in 22/44 checks). Reward/mean min ~896.15, max ~1916.35, last ~1626.05; format reward recovered to 1.0; truncation max 0.25 then 0.0 at end; completion_len/mean min ~2799.75, max ~7846.0, last ~6422.75. Logs show no sample-upload 500s; one transient server-sync/model-query connection error self-recovered. **Criteria verdict:** round progression PASS; plan quality PARTIAL; no exploit-spike signal PASS; episode length still cap-limited/inconclusive at 18.
- Run X75 (v0.2.19, max_rounds=40, batch_size=1, branching) completed with samples at steps 0/10/20/30/40/50 (step samples: 1/1/1/1/1/1). Parsed all rollouts and all turns: 6 samples, plan length always 2 (138/138), invalid_plan=0, choose_out_of_range=0. Action mix was strongly upgrade-dominant (upgrade=250, build=25, noop=1), and candidate availability was similarly skewed (upgrade=272, build=38, noop=138). By phase (snapshots at rounds 16/20, effectively late-only): late build 25 vs upgrade 250 (~900% upgrade lead; build share ~9%) - **plan quality fail** adaptive late target (build floor missed; upgrade lead far above band). Round progression: all non-cap checks passed (`delta_round == 1` for 126/126, 0 missing, 0 pre-cap failures); cap-bound observations at round 40 were split (`delta_round=0` in 6/12 checks). Reward/mean min ~277.30, max ~5222.10, last ~3878.40; format reward 1.0; truncation 0; completion_len/mean min ~35.0, max ~22489.0, last ~18675.0; num_turns max/last 25/21. No sample-upload 500s or logged runtime errors. **Criteria verdict:** round progression PASS; plan quality FAIL; horizon lower-bound PASS (`true horizon >= 40`); beyond-cap episode length still unresolved by right-censoring.
- Run X76 (v0.2.19, max_rounds=18, batch_size=4, branching) completed with samples at steps 0/10/20/30/40/50 (step samples: 4/4/4/4/4/4). Parsed all rollouts and all turns: 24 samples, plan length always 2 (132/132), invalid_plan=0, choose_out_of_range=0. Action mix was slightly upgrade-leaning overall (upgrade=137, build=127), with an upgrade-skewed candidate pool (upgrade=402 vs build=271; noop candidates=132). By phase (round-mapped with early<=11, mid<=13): mid build 48 vs upgrade 12 (**build-leaning mid**), late build 79 vs upgrade 125 (**late upgrade-leaning with build presence**, ~58% upgrade lead) - **plan quality partial** (direction is correct, but upgrade lead remains above preferred 15-25% band). Round progression: all non-cap checks passed (`delta_round == 1` for 84/84, 0 missing, 0 pre-cap failures); cap-bound observations at round 18 were split (`delta_round=0` in 24/48 checks). Reward/mean min ~902.15, max ~1872.35, last ~938.40; format reward 1.0; truncation 0; completion_len/mean min ~2668.0, max ~7729.5, last ~2772.25. No sample-upload 500s or logged runtime errors. **Criteria verdict:** round progression PASS; plan quality PARTIAL; no exploit-spike signal PASS; episode length still cap-limited/inconclusive at 18.
- Run X77 (v0.2.19, max_rounds=42, batch_size=1, branching) completed with samples at steps 0/10/20/30/40/50 (step samples: 1/1/1/1/1/1). Parsed all rollouts and all turns: 6 samples, plan length always 2 (154/154), invalid_plan=0, choose_out_of_range=0. Action mix remained strongly upgrade-dominant (upgrade=285, build=23), and candidate availability was similarly skewed (upgrade=302, build=34, noop=154). By phase (snapshots at rounds 16/20, effectively late-only): late build 23 vs upgrade 285 (~1139% upgrade lead; build share ~7%) - **plan quality fail** adaptive late target (build floor missed; upgrade lead far above band). Round progression: all non-cap checks passed (`delta_round == 1` for 142/142, 0 missing, 0 pre-cap failures); cap-bound observations at round 42 were split (`delta_round=0` in 6/12 checks). Reward/mean min ~3098.40, max ~11643.10, last ~5216.90; format reward 1.0; truncation 0; completion_len/mean min ~13797.0, max ~25103.0, last ~20523.0; num_turns max/last 27/23. No sample-upload 500s or logged runtime errors. **Criteria verdict:** round progression PASS; plan quality FAIL; horizon lower-bound PASS (`true horizon >= 42`); beyond-cap episode length remains unresolved by right-censoring.
- Decision update (2026-02-03): SingleTurn diagnostics concluded after W; macro-round multi-turn is now the primary training path.
- Decision update (2026-02-04): all future Prime TD runs should use `trajectory_strategy="branching"` unless explicitly overridden for experiments.
- Decision update (2026-02-05): X28/X29 will run in parallel to probe **episode length** with minimal payload risk. X28 raises `max_rounds=18` while keeping X26d payload controls; X29 keeps the same caps but nudges late-phase candidate balance (late `min_build_frac=0.45`, late `max_upgrade_candidates=7`) to improve late mix without increasing payload size.
- Decision update (2026-02-05): proceed to the **next stage** despite episode-length remaining **inconclusive** due to intermittent 500s at higher payloads; defer length testing until PI fixes the upload issue.
- Decision update (2026-02-05): next-stage runs will use **X26d behavioral baseline** (best plan quality so far) under **X29b payload controls** to keep uploads stable; run X30/X31 in parallel with a minimal late-phase mix nudge in X31.
- Decision update (2026-02-05): late-game upgrades are **expected** as rounds harden; refine plan-quality target to **early build-heavy**, **mid mixed**, **late upgrade-leaning but with some build actions** (to allow specialized towers).
- Decision update (2026-02-05): `batch_size=2` mitigated upload 500s for max_round probes (X46b/X47b), but both runs saturated at cap (24/26), so episode-length improvement beyond cap remains **inconclusive**.
- Decision update (2026-02-06): X49 extended the stable horizon to round-cap 28 (all parsed rollouts ended at 28), but the step-40 sample-upload 500 and cap saturation still leave true episode-length gains beyond cap **unresolved**.
- Decision update (2026-02-06): for next configs, treat late `10-15%` upgrade lead as a **minimum** signal rather than a fixed optimum; prefer an adaptive late target around **15-25%** upgrade lead with enforced build presence (late build share roughly **25-35%**) to balance survivability and avoid upgrade-only policy collapse.
- Decision update (2026-02-06): X51 (`max_rounds=30`) confirms that horizon extension can re-trigger sample-upload 500 failures even at `batch_size=2`; keep two-track evaluation (behavior at stable horizon + separate horizon probe) and treat missing-rollout runs as infra-limited/non-diagnostic for policy quality.
- Decision update (2026-02-06): X52 is the new behavior-lane reference for adaptive late mix (~15% late upgrade lead with build present), while X53 shows that stricter payload caps can recover some horizon samples but may over-constrain late build opportunities and still intermittently 500 at sample upload.
- Decision update (2026-02-06): X54 confirms the current center-point calibration can over-correct into late build-leaning behavior; retain X52 as behavior-lane reference for now.
- Decision update (2026-02-06): X55 reaches round-cap 30 on all parsed rollouts, but intermittent sample-upload 500s (missing steps 0/30/50) and cap saturation keep episode-length gains beyond cap **inconclusive**.
- Decision update (2026-02-06): for episode-length testing, use a reliability-first horizon lane (smaller upload payload per sample, e.g., `batch_size=1` and later snapshots) in parallel with behavior-lane calibration anchored on X52; avoid large YOLO runs until sample-upload stability improves.
- Decision update (2026-02-06): X56 re-confirmed that naive re-anchoring can drift into late build-leaning behavior; keep X52 as behavior-lane baseline for late-phase targeting.
- Decision update (2026-02-06): X57 validated the reliability-first horizon approach (`batch_size=1`, later snapshots) with full sample-step coverage and no upload 500s at `max_rounds=30`, but policy quality remained late over-upgrade, so horizon and behavior lanes should stay decoupled.
- Decision update (2026-02-06): X58 shows that increasing late `max_upgrade_candidates` can correct build-lean drift (late direction fixed) but may overshoot into too-strong upgrade lead; next behavior-lane tweak should tighten toward the 15-25% lead band.
- Decision update (2026-02-06): X59 extends reliability-first horizon execution to `max_rounds=32` with full sample-step coverage and no upload 500s; true episode-length gain beyond cap is still unobservable, so future horizon claims should require raising cap again under the same reliability controls.
- Decision update (2026-02-06): X60 kept late-phase direction upgrade-leaning with build presence but did not tighten the lead band enough; keep behavior lane anchored around X52 and continue small late-floor/candidate adjustments.
- Decision update (2026-02-06): X61 extends reliability-first horizon execution to `max_rounds=34` with full sample-step coverage and no upload 500s; horizon infra is stable, but true beyond-cap episode-length gains remain unobserved until a higher cap run stops saturating.
- Decision update (2026-02-06): X62 improved late-phase balance toward parity and preserved build presence with zero 500s, but the late upgrade lead (~7%) is below the preferred 15-25% band; next behavior-lane tweak should slightly reduce late build floor or modestly increase late upgrade candidate pressure.
- Decision update (2026-02-06): X63 extends horizon-lane cap saturation to `max_rounds=36` on all parsed samples, but one step-20 sample-upload 500 confirms horizon runs remain infra-sensitive at high completion payloads; treat horizon signal as lower-bound progress, not beyond-cap proof.
- Decision update (2026-02-06): X65 confirms the reliability-first horizon lane can run `max_rounds=36` with full sample checkpoints and no upload 500s under reduced payload caps; keep those controls fixed and raise cap gradually for horizon probing, while X66 should tighten behavior-lane late-phase pressure slightly from X64 to target a 15-25% upgrade lead.
- Decision update (2026-02-07): X66 achieved the target late-phase behavior at the lower bound (~15% upgrade lead with build presence), so use X66 as the behavior-lane baseline for the next pair. X67 reached cap 38 but had sample-upload 500s at steps 0/20/40; keep the horizon lane on X65 payload controls and either retry cap 38 or reduce completion payload further before raising cap again.
- Decision update (2026-02-07): X68 confirms the X66-anchored behavior lane remains stable but a small late-floor nudge (`min_build_frac=0.37`) can overshoot the preferred band (~31% late upgrade lead); keep X66 as behavior baseline and use smaller late-pressure deltas.
- Decision update (2026-02-07): X69 shows that even tighter observation payload caps still hit intermittent sample-upload 500 at high-horizon cap 38 when completion payload remains large (~20k-26k tokens/sample); treat horizon evidence as lower-bound only and keep infra-risk explicitly tracked in pass/fail calls.
- Decision update (2026-02-07): X70 meets behavior-lane criteria at the upper bound of the preferred late-phase band (~24% upgrade lead with strong build presence), so keep X66 and X70 as stable lower/upper anchors for late-mix tuning.
- Decision update (2026-02-07): X71 indicates `sampling.max_tokens=32` is below safe macro-plan output budget for the current prompt/observation regime; keep horizon lane at `max_tokens>=40` and treat sub-40 settings as high risk for truncation-driven policy collapse.
- Decision update (2026-02-07): X72 reproduces upper-band behavior-lane success (~25% late upgrade lead with build presence) under stable payload controls, confirming X66 (lower bound) and X70/X72 (upper bound) as robust calibration anchors.
- Decision update (2026-02-07): X73 restores horizon-lane reliability at `max_rounds=38` with full sample coverage and no upload 500s when `max_tokens` is returned to 40; keep this as the new horizon baseline, while treating episode-length gain beyond cap as still unresolved.
- Decision update (2026-02-07): X74 is a viable behavior-lane fallback with cleaner mid/late structure and stable infra, but late upgrade lead (~31%) is still above target; keep X66/X70/X72 as primary behavior anchors and treat X74 as an upper-pressure reference.
- Decision update (2026-02-07): X75 extends the reliability-first horizon lower bound to `>=40` with full sample checkpoints and no upload 500s; continue horizon probing by raising cap incrementally under the same payload controls, while keeping beyond-cap episode length claims explicitly unresolved until a non-cap-stop run is observed.
- Decision update (2026-02-07): X76 re-confirms stable behavior-lane infrastructure with full sample coverage and clean round progression, but its late upgrade lead (~58%) still overshoots target; keep X66/X70/X72 as calibration anchors and use smaller late-pressure changes.
- Decision update (2026-02-07): X77 extends the reliability-first horizon lower bound to `>=42` with full sample checkpoints and no upload 500s; continue cap-raising horizon probes under unchanged payload controls, while keeping true beyond-cap episode-length claims unresolved until a non-cap-stop run is observed.

## Q/R Rollout Snippets (diagnostic detail)

Notes:
- Step indices below are **training steps**, not environment steps.
- Reward breakdown + counterfactuals are replayed from logged observations with the run config (auto-advance on), to make action tradeoffs explicit.
- No samples in Q/R rollouts had `prep_actions_remaining > 1` (all were `1`).

### Run Q (v0.2.7) metadata
- **Config:** `configs/lab/prime-td-auto-advance-80-q.toml`
- **Dataset policy:** `noop_then_start`, `rollout_steps=9`
- **Rules:** `auto_advance_round=true`, `prep_actions_per_round=2`, `prep_actions_round_scale=0.0`, `prep_actions_max=6`
- **start_round_max_prep_remaining:** unset (no gating)

**Q step 0 (training step)** — action `{"type":"build","tower_type":"dart","x":1,"y":3}`
- **State:** round=5, `prep_actions_remaining=1`, cash=902, lives=100
- **Towers:** id 1 dart upgrades:none @(0,4)
- **valid_actions.start_round:** true
- **Reward breakdown:** pop_reward=38.0, end_round_income=100.0, life_loss_penalty=0.0, invalid_action_penalty=0.0, step_penalty=-0.1
- **Simulated round:** yes; **auto-advance credit fix:** no (round already simulated)
- **Counterfactual:** `start_round` would yield ~9.9 reward with ~10 lives lost; best build yields ~137.9 reward with 0 lives lost.

**Q step 40 (training step)** — action `{"type":"start_round"}`
- **State:** round=5, `prep_actions_remaining=1`, cash=902, lives=100
- **Towers:** id 1 dart upgrades:none @(0,5)
- **valid_actions.start_round:** true
- **Reward breakdown:** pop_reward=10.0, end_round_income=100.0, life_loss_penalty=-100.0, invalid_action_penalty=0.0, step_penalty=-0.1
- **Simulated round:** yes; **auto-advance credit fix:** no
- **Counterfactual:** best build yields ~137.9 reward with 0 lives lost vs `start_round` ~9.9 reward with ~10 lives lost.

**Q step 70 (training step)** — action `{"type":"start_round"}`
- **State:** round=5, `prep_actions_remaining=1`, cash=902, lives=100
- **Towers:** id 1 dart upgrades:none @(0,4)
- **valid_actions.start_round:** true
- **Reward breakdown:** pop_reward=12.0, end_round_income=100.0, life_loss_penalty=-80.0, invalid_action_penalty=0.0, step_penalty=-0.1
- **Simulated round:** yes; **auto-advance credit fix:** no
- **Counterfactual:** best build yields ~133.9 reward with 0 lives lost vs `start_round` ~31.9 reward with ~8 lives lost.

### Run R (v0.2.7) metadata
- **Config:** `configs/lab/prime-td-auto-advance-80-r.toml`
- **Dataset policy:** `noop_then_start`, `rollout_steps=9`
- **Rules:** `auto_advance_round=true`, `prep_actions_per_round=2`, `prep_actions_round_scale=0.0`, `prep_actions_max=6`
- **start_round_max_prep_remaining:** 1

**R step 0 (training step)** — action `{"type":"build","tower_type":"dart","x":1,"y":5}` (invalid_position)
- **State:** round=5, `prep_actions_remaining=1`, cash=902, lives=100
- **Towers:** id 1 dart upgrades:none @(0,5)
- **valid_actions.start_round:** true
- **Reward breakdown:** pop_reward=10.0, end_round_income=100.0, life_loss_penalty=-100.0, invalid_action_penalty=-1.0, step_penalty=-0.1
- **Simulated round:** yes; **auto-advance credit fix:** no
- **Counterfactual:** best build yields ~137.9 reward with 0 lives lost; `start_round` ~9.9 reward with ~10 lives lost.

**R step 40 (training step)** — action `{"type":"build","tower_type":"dart","x":1,"y":7}` (invalid_position)
- **State:** round=5, `prep_actions_remaining=1`, cash=902, lives=100
- **Towers:** id 1 dart upgrades:none @(0,5)
- **valid_actions.start_round:** true
- **Reward breakdown:** pop_reward=9.0, end_round_income=100.0, life_loss_penalty=-110.0, invalid_action_penalty=-1.0, step_penalty=-0.1
- **Simulated round:** yes; **auto-advance credit fix:** no
- **Counterfactual:** best build yields ~139.9 reward with 0 lives lost vs `start_round` ~-1.1 reward with ~11 lives lost.

**R step 70 (training step)** — action `{"type":"build","tower_type":"dart","x":1,"y":4}`
- **State:** round=5, `prep_actions_remaining=1`, cash=902, lives=100
- **Towers:** id 1 dart upgrades:none @(0,5)
- **valid_actions.start_round:** true
- **Reward breakdown:** pop_reward=32.0, end_round_income=100.0, life_loss_penalty=0.0, invalid_action_penalty=0.0, step_penalty=-0.1
- **Simulated round:** yes; **auto-advance credit fix:** no
- **Counterfactual:** best build yields ~131.9 reward with 0 lives lost vs `start_round` ~42.9 reward with ~7 lives lost.

## S/T Rollout Snippets (diagnostic detail)

Notes:
- Step indices below are **training steps**, not environment steps.
- Reward breakdown + counterfactuals are replayed from logged observations with the run config (auto-advance on), to make action tradeoffs explicit.
- No samples in S/T rollouts had `prep_actions_remaining > 1` (all were `1`).

### Run S (v0.2.10) metadata
- **Config:** `configs/lab/prime-td-auto-advance-80-s.toml`
- **Dataset policy:** `noop_then_start`, `rollout_steps=9`
- **Rules:** `auto_advance_round=true`, `prep_actions_per_round=2`, `prep_actions_round_scale=0.0`, `prep_actions_max=6`
- **start_round_max_prep_remaining:** 1

**S step 0 (training step)** — action `{"type":"build","tower_type":"dart","x":1,"y":4}`
- **State:** round=5, `prep_actions_remaining=1`, cash=902, lives=100
- **Towers:** id 1 dart upgrades:none @(0,4)
- **valid_actions.start_round:** true
- **Reward breakdown:** pop_reward=40.0, end_round_income=100.0, life_loss_penalty=0.0, invalid_action_penalty=0.0, step_penalty=-0.1
- **Simulated round:** yes; **auto-advance credit fix:** no
- **Counterfactual:** `start_round` would yield ~-1.1 reward with ~11 lives lost; best build yields ~139.9 reward with 0 lives lost.

**S step 40 (training step)** — action `{"type":"build","tower_type":"dart","x":1,"y":0}`
- **State:** round=5, `prep_actions_remaining=1`, cash=902, lives=100
- **Towers:** id 1 dart upgrades:none @(0,0)
- **valid_actions.start_round:** true
- **Reward breakdown:** pop_reward=34.0, end_round_income=100.0, life_loss_penalty=0.0, invalid_action_penalty=0.0, step_penalty=-0.1
- **Simulated round:** yes; **auto-advance credit fix:** no
- **Counterfactual:** `start_round` would yield ~31.9 reward with ~8 lives lost; best build yields ~133.9 reward with 0 lives lost.

**S step 70 (training step)** — action `{"type":"build","tower_type":"dart","x":1,"y":3}`
- **State:** round=5, `prep_actions_remaining=1`, cash=902, lives=100
- **Towers:** id 1 dart upgrades:none @(0,3)
- **valid_actions.start_round:** true
- **Reward breakdown:** pop_reward=28.0, end_round_income=100.0, life_loss_penalty=0.0, invalid_action_penalty=0.0, step_penalty=-0.1
- **Simulated round:** yes; **auto-advance credit fix:** no
- **Counterfactual:** `start_round` would yield ~64.9 reward with ~5 lives lost; best build yields ~127.9 reward with 0 lives lost.

### Run T (v0.2.10) metadata
- **Config:** `configs/lab/prime-td-auto-advance-80-t.toml`
- **Dataset policy:** `noop_then_start`, `rollout_steps=9`
- **Rules:** `auto_advance_round=true`, `prep_actions_per_round=2`, `prep_actions_round_scale=0.0`, `prep_actions_max=6`
- **start_round_max_prep_remaining:** 1
- **Economy:** `starting_cash=200`, `end_round_income=30`

**T step 0 (training step)** — action `{"type":"upgrade","tower_id":1,"path":"a"}`
- **State:** round=5, `prep_actions_remaining=1`, cash=172, lives=100
- **Towers:** id 1 dart upgrades:none @(0,1)
- **valid_actions.start_round:** true
- **Reward breakdown:** pop_reward=28.0, end_round_income=30.0, life_loss_penalty=-20.0, invalid_action_penalty=0.0, step_penalty=-0.1
- **Simulated round:** yes; **auto-advance credit fix:** no
- **Counterfactual:** `start_round` would yield ~-38.1 reward with ~8 lives lost; best upgrade yields ~37.9 reward with ~2 lives lost.

**T step 40 (training step)** — action `{"type":"upgrade","tower_id":1,"path":"a"}`
- **State:** round=5, `prep_actions_remaining=1`, cash=172, lives=100
- **Towers:** id 1 dart upgrades:none @(0,1)
- **valid_actions.start_round:** true
- **Reward breakdown:** pop_reward=35.0, end_round_income=30.0, life_loss_penalty=-50.0, invalid_action_penalty=0.0, step_penalty=-0.1
- **Simulated round:** yes; **auto-advance credit fix:** no
- **Counterfactual:** `start_round` would yield ~-71.1 reward with ~11 lives lost; best upgrade yields ~14.9 reward with ~5 lives lost.

**T step 70 (training step)** — action `{"type":"upgrade","tower_id":1,"path":"a"}`
- **State:** round=5, `prep_actions_remaining=1`, cash=172, lives=100
- **Towers:** id 1 dart upgrades:none @(0,0)
- **valid_actions.start_round:** true
- **Reward breakdown:** pop_reward=31.0, end_round_income=30.0, life_loss_penalty=-30.0, invalid_action_penalty=0.0, step_penalty=-0.1
- **Simulated round:** yes; **auto-advance credit fix:** no
- **Counterfactual:** `start_round` would yield ~-38.1 reward with ~8 lives lost; best upgrade yields ~30.9 reward with ~3 lives lost.

## Repro Commands (to fill once run completes)

- Collect artifacts: `scripts/collect_prime_run_artifacts.sh <RUN_ID>`
- Held-out eval: `python3 scripts/eval.py --eval-seed-start 1000 --eval-seed-count 50 --random-seed-start 2000 --random-seed-count 20 --max-rounds 20 --max-steps 200 --output-dir out/eval`
